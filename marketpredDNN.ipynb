{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "marketpredDNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1kJGWLxhzGKHWdk/R3Xx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhcool1988/teamdata/blob/master/marketpredDNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlzQv0j506qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a6ca4ea6-b5a5-4dbf-c189-07de809b5c23"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vunYUe2M1TiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data():\n",
        "    #get train data\n",
        "    train_data_path ='https://raw.githubusercontent.com/jhcool1988/teamdata/master/soccerVFm.csv'\n",
        "    train = pd.read_csv(train_data_path)\n",
        "    train = train[['mvpr','goal','assist','sh','int','drib']]\n",
        "    #get test data\n",
        "    test_data_path ='https://raw.githubusercontent.com/jhcool1988/teamdata/master/soccerVFm.csv'\n",
        "    test = pd.read_csv(test_data_path)\n",
        "    test = test[['goal','assist','sh','int','drib']]\n",
        "    return train , test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhZjwQSR2Hf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_combined_data():\n",
        "  #reading train data\n",
        "  train , test = get_data()\n",
        "\n",
        "  target = train.mvpr\n",
        "  train.drop(['mvpr'],axis = 1 , inplace = True)\n",
        "\n",
        "  combined = train.append(test)\n",
        "  combined.reset_index(inplace=True)\n",
        "  combined.drop(['index'], inplace=True, axis=1)\n",
        "  return combined, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZp8Xea22y2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load train and test data into pandas DataFrames\n",
        "train_data, test_data = get_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv_S1gbU201u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combine train and test data to process them together\n",
        "combined, target = get_combined_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1LKsBr723s-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "5df73e1d-f2b9-468f-9dc4-e2af2db0e3bf"
      },
      "source": [
        "combined.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>goal</th>\n",
              "      <th>assist</th>\n",
              "      <th>sh</th>\n",
              "      <th>int</th>\n",
              "      <th>drib</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2370.000000</td>\n",
              "      <td>2370.000000</td>\n",
              "      <td>2370.000000</td>\n",
              "      <td>2370.000000</td>\n",
              "      <td>2370.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.007595</td>\n",
              "      <td>2.868354</td>\n",
              "      <td>38.935949</td>\n",
              "      <td>14.927426</td>\n",
              "      <td>4.903797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6.099286</td>\n",
              "      <td>2.904337</td>\n",
              "      <td>25.117012</td>\n",
              "      <td>11.564993</td>\n",
              "      <td>5.260863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>36.200000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              goal       assist           sh          int         drib\n",
              "count  2370.000000  2370.000000  2370.000000  2370.000000  2370.000000\n",
              "mean      6.007595     2.868354    38.935949    14.927426     4.903797\n",
              "std       6.099286     2.904337    25.117012    11.564993     5.260863\n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000\n",
              "25%       1.000000     1.000000    23.000000     6.000000     1.000000\n",
              "50%       4.000000     2.000000    36.200000    13.000000     3.000000\n",
              "75%       9.000000     4.000000    49.000000    21.000000     7.000000\n",
              "max      36.000000    21.000000   194.000000    70.000000    39.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcovHXFU32Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cols_with_no_nans(df,col_type):\n",
        "    '''\n",
        "    Arguments :\n",
        "    df : The dataframe to process\n",
        "    col_type : \n",
        "          num : to only get numerical columns with no nans\n",
        "          no_num : to only get nun-numerical columns with no nans\n",
        "          all : to get any columns with no nans    \n",
        "    '''\n",
        "    if (col_type == 'num'):\n",
        "        predictors = df.select_dtypes(exclude=['object'])\n",
        "    elif (col_type == 'no_num'):\n",
        "        predictors = df.select_dtypes(include=['object'])\n",
        "    elif (col_type == 'all'):\n",
        "        predictors = df\n",
        "    else :\n",
        "        print('Error : choose a type (num, no_num, all)')\n",
        "        return 0\n",
        "    cols_with_no_nans = []\n",
        "    for col in predictors.columns:\n",
        "        if not df[col].isnull().any():\n",
        "            cols_with_no_nans.append(col)\n",
        "    return cols_with_no_nans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tDDDc0t3_8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cols = get_cols_with_no_nans(combined , 'num')\n",
        "cat_cols = get_cols_with_no_nans(combined , 'no_num')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlC8KY214CDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bf3fd668-be67-4b9e-cacd-d3c5d957847a"
      },
      "source": [
        "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
        "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of numerical columns with no nan values : 5\n",
            "Number of nun-numerical columns with no nan values : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8hCSCGZ4FTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "0e1e65de-af62-499a-a6ff-85d34f3197e3"
      },
      "source": [
        "combined = combined[num_cols + cat_cols]\n",
        "combined.hist(figsize = (12,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3oVXYW4JMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "d7493ecd-6cd4-405c-8996-6ce4a7f8b96b"
      },
      "source": [
        "train_data = train_data[num_cols + cat_cols]\n",
        "train_data['Target'] = target\n",
        "\n",
        "C_mat = train_data.corr()\n",
        "fig = plt.figure(figsize = (15,15))\n",
        "\n",
        "sb.heatmap(C_mat, vmax = .8, square = True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-PRXrY-4PUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def oneHotEncode(df,colNames):\n",
        "    for col in colNames:\n",
        "        if( df[col].dtype == np.dtype('object')):\n",
        "            dummies = pd.get_dummies(df[col],prefix=col)\n",
        "            df = pd.concat([df,dummies],axis=1)\n",
        "\n",
        "            #drop the encoded column\n",
        "            df.drop([col],axis = 1 , inplace=True)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaLyFUb14RGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ac7bf608-c08b-4106-84bd-4a689f29b58e"
      },
      "source": [
        "print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\n",
        "combined = oneHotEncode(combined, cat_cols)\n",
        "print('There are {} columns after encoding categorical features'.format(combined.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There were 5 columns before encoding categorical features\n",
            "There are 5 columns after encoding categorical features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElDMTIt-4TVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_combined():\n",
        "    global combined\n",
        "    train = combined[:800]\n",
        "    test = combined[800:]\n",
        "\n",
        "    return train , test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMnSYDrZ4ZTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = split_combined()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-O2ps8o4bfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea982243-3677-41cc-c801-fbf6d5e1c2a5"
      },
      "source": [
        "NN_model = Sequential()\n",
        "\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
        "\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "\n",
        "\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "\n",
        "# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = NN_model.fit(train, target, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n",
        "\n",
        "NN_model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 24915778.0000 - mean_absolute_error: 24915778.0000\n",
            "Epoch 00001: val_loss improved from inf to 11869534.00000, saving model to Weights-001--11869534.00000.hdf5\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 24710648.0000 - mean_absolute_error: 24710648.0000 - val_loss: 11869534.0000 - val_mean_absolute_error: 11869534.0000\n",
            "Epoch 2/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 24388452.0000 - mean_absolute_error: 24388452.0000\n",
            "Epoch 00002: val_loss improved from 11869534.00000 to 11867190.00000, saving model to Weights-002--11867190.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 24709546.0000 - mean_absolute_error: 24709546.0000 - val_loss: 11867190.0000 - val_mean_absolute_error: 11867190.0000\n",
            "Epoch 3/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 24772474.0000 - mean_absolute_error: 24772474.0000\n",
            "Epoch 00003: val_loss improved from 11867190.00000 to 11842398.00000, saving model to Weights-003--11842398.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 24694172.0000 - mean_absolute_error: 24694172.0000 - val_loss: 11842398.0000 - val_mean_absolute_error: 11842398.0000\n",
            "Epoch 4/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 24585368.0000 - mean_absolute_error: 24585368.0000\n",
            "Epoch 00004: val_loss improved from 11842398.00000 to 11696683.00000, saving model to Weights-004--11696683.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 24585368.0000 - mean_absolute_error: 24585368.0000 - val_loss: 11696683.0000 - val_mean_absolute_error: 11696683.0000\n",
            "Epoch 5/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 23881380.0000 - mean_absolute_error: 23881380.0000\n",
            "Epoch 00005: val_loss improved from 11696683.00000 to 11121202.00000, saving model to Weights-005--11121202.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 24092170.0000 - mean_absolute_error: 24092170.0000 - val_loss: 11121202.0000 - val_mean_absolute_error: 11121202.0000\n",
            "Epoch 6/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 23002800.0000 - mean_absolute_error: 23002800.0000\n",
            "Epoch 00006: val_loss improved from 11121202.00000 to 9567315.00000, saving model to Weights-006--9567315.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 22464240.0000 - mean_absolute_error: 22464240.0000 - val_loss: 9567315.0000 - val_mean_absolute_error: 9567315.0000\n",
            "Epoch 7/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 19240560.0000 - mean_absolute_error: 19240560.0000\n",
            "Epoch 00007: val_loss improved from 9567315.00000 to 7836819.00000, saving model to Weights-007--7836819.00000.hdf5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 19030336.0000 - mean_absolute_error: 19030336.0000 - val_loss: 7836819.0000 - val_mean_absolute_error: 7836819.0000\n",
            "Epoch 8/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 16153435.0000 - mean_absolute_error: 16153435.0000\n",
            "Epoch 00008: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15832842.0000 - mean_absolute_error: 15832842.0000 - val_loss: 7985504.0000 - val_mean_absolute_error: 7985504.0000\n",
            "Epoch 9/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 15184592.0000 - mean_absolute_error: 15184592.0000\n",
            "Epoch 00009: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15231502.0000 - mean_absolute_error: 15231502.0000 - val_loss: 8228650.5000 - val_mean_absolute_error: 8228650.5000\n",
            "Epoch 10/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15219857.0000 - mean_absolute_error: 15219857.0000\n",
            "Epoch 00010: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15235254.0000 - mean_absolute_error: 15235254.0000 - val_loss: 8036390.5000 - val_mean_absolute_error: 8036390.5000\n",
            "Epoch 11/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 15180782.0000 - mean_absolute_error: 15180782.0000\n",
            "Epoch 00011: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15180782.0000 - mean_absolute_error: 15180782.0000 - val_loss: 7994902.5000 - val_mean_absolute_error: 7994902.5000\n",
            "Epoch 12/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 15151438.0000 - mean_absolute_error: 15151438.0000\n",
            "Epoch 00012: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15151438.0000 - mean_absolute_error: 15151438.0000 - val_loss: 7954497.5000 - val_mean_absolute_error: 7954497.5000\n",
            "Epoch 13/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15335188.0000 - mean_absolute_error: 15335188.0000\n",
            "Epoch 00013: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15150528.0000 - mean_absolute_error: 15150528.0000 - val_loss: 8011177.5000 - val_mean_absolute_error: 8011177.5000\n",
            "Epoch 14/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 15110525.0000 - mean_absolute_error: 15110525.0000\n",
            "Epoch 00014: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15110525.0000 - mean_absolute_error: 15110525.0000 - val_loss: 7940573.5000 - val_mean_absolute_error: 7940573.5000\n",
            "Epoch 15/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15112778.0000 - mean_absolute_error: 15112778.0000\n",
            "Epoch 00015: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15096174.0000 - mean_absolute_error: 15096174.0000 - val_loss: 8062313.5000 - val_mean_absolute_error: 8062313.5000\n",
            "Epoch 16/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 15158798.0000 - mean_absolute_error: 15158798.0000\n",
            "Epoch 00016: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15063635.0000 - mean_absolute_error: 15063635.0000 - val_loss: 7990755.0000 - val_mean_absolute_error: 7990755.0000\n",
            "Epoch 17/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15216802.0000 - mean_absolute_error: 15216802.0000\n",
            "Epoch 00017: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15040259.0000 - mean_absolute_error: 15040259.0000 - val_loss: 7994813.5000 - val_mean_absolute_error: 7994813.5000\n",
            "Epoch 18/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15209090.0000 - mean_absolute_error: 15209090.0000\n",
            "Epoch 00018: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15016832.0000 - mean_absolute_error: 15016832.0000 - val_loss: 7937371.0000 - val_mean_absolute_error: 7937371.0000\n",
            "Epoch 19/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14772579.0000 - mean_absolute_error: 14772579.0000\n",
            "Epoch 00019: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 15007336.0000 - mean_absolute_error: 15007336.0000 - val_loss: 7844633.5000 - val_mean_absolute_error: 7844633.5000\n",
            "Epoch 20/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 15211413.0000 - mean_absolute_error: 15211413.0000\n",
            "Epoch 00020: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14991158.0000 - mean_absolute_error: 14991158.0000 - val_loss: 7991025.5000 - val_mean_absolute_error: 7991025.5000\n",
            "Epoch 21/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14949926.0000 - mean_absolute_error: 14949926.0000\n",
            "Epoch 00021: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14972123.0000 - mean_absolute_error: 14972123.0000 - val_loss: 7932189.0000 - val_mean_absolute_error: 7932189.0000\n",
            "Epoch 22/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14933518.0000 - mean_absolute_error: 14933518.0000\n",
            "Epoch 00022: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14933518.0000 - mean_absolute_error: 14933518.0000 - val_loss: 7842301.5000 - val_mean_absolute_error: 7842301.5000\n",
            "Epoch 23/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15080138.0000 - mean_absolute_error: 15080138.0000\n",
            "Epoch 00023: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14913378.0000 - mean_absolute_error: 14913378.0000 - val_loss: 7930953.5000 - val_mean_absolute_error: 7930953.5000\n",
            "Epoch 24/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14893323.0000 - mean_absolute_error: 14893323.0000\n",
            "Epoch 00024: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14893323.0000 - mean_absolute_error: 14893323.0000 - val_loss: 7917005.0000 - val_mean_absolute_error: 7917005.0000\n",
            "Epoch 25/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14874130.0000 - mean_absolute_error: 14874130.0000\n",
            "Epoch 00025: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14874130.0000 - mean_absolute_error: 14874130.0000 - val_loss: 7876664.0000 - val_mean_absolute_error: 7876664.0000\n",
            "Epoch 26/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 15024672.0000 - mean_absolute_error: 15024672.0000\n",
            "Epoch 00026: val_loss did not improve from 7836819.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14867846.0000 - mean_absolute_error: 14867846.0000 - val_loss: 7943453.0000 - val_mean_absolute_error: 7943453.0000\n",
            "Epoch 27/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 15035277.0000 - mean_absolute_error: 15035277.0000\n",
            "Epoch 00027: val_loss improved from 7836819.00000 to 7767197.00000, saving model to Weights-027--7767197.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14858752.0000 - mean_absolute_error: 14858752.0000 - val_loss: 7767197.0000 - val_mean_absolute_error: 7767197.0000\n",
            "Epoch 28/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14581336.0000 - mean_absolute_error: 14581336.0000\n",
            "Epoch 00028: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14859477.0000 - mean_absolute_error: 14859477.0000 - val_loss: 7848816.0000 - val_mean_absolute_error: 7848816.0000\n",
            "Epoch 29/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14609814.0000 - mean_absolute_error: 14609814.0000\n",
            "Epoch 00029: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14808720.0000 - mean_absolute_error: 14808720.0000 - val_loss: 7787888.0000 - val_mean_absolute_error: 7787888.0000\n",
            "Epoch 30/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14880593.0000 - mean_absolute_error: 14880593.0000\n",
            "Epoch 00030: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14775939.0000 - mean_absolute_error: 14775939.0000 - val_loss: 7807451.0000 - val_mean_absolute_error: 7807451.0000\n",
            "Epoch 31/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13987381.0000 - mean_absolute_error: 13987381.0000\n",
            "Epoch 00031: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14753301.0000 - mean_absolute_error: 14753301.0000 - val_loss: 7858014.5000 - val_mean_absolute_error: 7858014.5000\n",
            "Epoch 32/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14741915.0000 - mean_absolute_error: 14741915.0000\n",
            "Epoch 00032: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14741915.0000 - mean_absolute_error: 14741915.0000 - val_loss: 7862552.0000 - val_mean_absolute_error: 7862552.0000\n",
            "Epoch 33/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14690885.0000 - mean_absolute_error: 14690885.0000\n",
            "Epoch 00033: val_loss did not improve from 7767197.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14712656.0000 - mean_absolute_error: 14712656.0000 - val_loss: 7790487.0000 - val_mean_absolute_error: 7790487.0000\n",
            "Epoch 34/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14872027.0000 - mean_absolute_error: 14872027.0000\n",
            "Epoch 00034: val_loss improved from 7767197.00000 to 7746049.50000, saving model to Weights-034--7746049.50000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14695285.0000 - mean_absolute_error: 14695285.0000 - val_loss: 7746049.5000 - val_mean_absolute_error: 7746049.5000\n",
            "Epoch 35/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14878187.0000 - mean_absolute_error: 14878187.0000\n",
            "Epoch 00035: val_loss did not improve from 7746049.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14686558.0000 - mean_absolute_error: 14686558.0000 - val_loss: 7833747.0000 - val_mean_absolute_error: 7833747.0000\n",
            "Epoch 36/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14729194.0000 - mean_absolute_error: 14729194.0000\n",
            "Epoch 00036: val_loss did not improve from 7746049.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14650704.0000 - mean_absolute_error: 14650704.0000 - val_loss: 7771981.5000 - val_mean_absolute_error: 7771981.5000\n",
            "Epoch 37/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 15077614.0000 - mean_absolute_error: 15077614.0000\n",
            "Epoch 00037: val_loss improved from 7746049.50000 to 7728161.00000, saving model to Weights-037--7728161.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14633078.0000 - mean_absolute_error: 14633078.0000 - val_loss: 7728161.0000 - val_mean_absolute_error: 7728161.0000\n",
            "Epoch 38/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14282845.0000 - mean_absolute_error: 14282845.0000\n",
            "Epoch 00038: val_loss did not improve from 7728161.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14617128.0000 - mean_absolute_error: 14617128.0000 - val_loss: 7751168.0000 - val_mean_absolute_error: 7751168.0000\n",
            "Epoch 39/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14388507.0000 - mean_absolute_error: 14388507.0000\n",
            "Epoch 00039: val_loss did not improve from 7728161.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14580043.0000 - mean_absolute_error: 14580043.0000 - val_loss: 7743397.5000 - val_mean_absolute_error: 7743397.5000\n",
            "Epoch 40/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14751421.0000 - mean_absolute_error: 14751421.0000\n",
            "Epoch 00040: val_loss did not improve from 7728161.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14568312.0000 - mean_absolute_error: 14568312.0000 - val_loss: 7788560.0000 - val_mean_absolute_error: 7788560.0000\n",
            "Epoch 41/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14567312.0000 - mean_absolute_error: 14567312.0000\n",
            "Epoch 00041: val_loss improved from 7728161.00000 to 7673673.50000, saving model to Weights-041--7673673.50000.hdf5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14548733.0000 - mean_absolute_error: 14548733.0000 - val_loss: 7673673.5000 - val_mean_absolute_error: 7673673.5000\n",
            "Epoch 42/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14124231.0000 - mean_absolute_error: 14124231.0000\n",
            "Epoch 00042: val_loss did not improve from 7673673.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14511800.0000 - mean_absolute_error: 14511800.0000 - val_loss: 7708587.0000 - val_mean_absolute_error: 7708587.0000\n",
            "Epoch 43/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14430185.0000 - mean_absolute_error: 14430185.0000\n",
            "Epoch 00043: val_loss did not improve from 7673673.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14505093.0000 - mean_absolute_error: 14505093.0000 - val_loss: 7758365.5000 - val_mean_absolute_error: 7758365.5000\n",
            "Epoch 44/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14541016.0000 - mean_absolute_error: 14541016.0000\n",
            "Epoch 00044: val_loss did not improve from 7673673.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14473240.0000 - mean_absolute_error: 14473240.0000 - val_loss: 7697393.5000 - val_mean_absolute_error: 7697393.5000\n",
            "Epoch 45/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14809156.0000 - mean_absolute_error: 14809156.0000\n",
            "Epoch 00045: val_loss improved from 7673673.50000 to 7672401.50000, saving model to Weights-045--7672401.50000.hdf5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14450078.0000 - mean_absolute_error: 14450078.0000 - val_loss: 7672401.5000 - val_mean_absolute_error: 7672401.5000\n",
            "Epoch 46/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14561471.0000 - mean_absolute_error: 14561471.0000\n",
            "Epoch 00046: val_loss did not improve from 7672401.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14416059.0000 - mean_absolute_error: 14416059.0000 - val_loss: 7677112.0000 - val_mean_absolute_error: 7677112.0000\n",
            "Epoch 47/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14022272.0000 - mean_absolute_error: 14022272.0000\n",
            "Epoch 00047: val_loss improved from 7672401.50000 to 7657949.00000, saving model to Weights-047--7657949.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14396242.0000 - mean_absolute_error: 14396242.0000 - val_loss: 7657949.0000 - val_mean_absolute_error: 7657949.0000\n",
            "Epoch 48/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14390349.0000 - mean_absolute_error: 14390349.0000\n",
            "Epoch 00048: val_loss did not improve from 7657949.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14366712.0000 - mean_absolute_error: 14366712.0000 - val_loss: 7683690.5000 - val_mean_absolute_error: 7683690.5000\n",
            "Epoch 49/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14239871.0000 - mean_absolute_error: 14239871.0000\n",
            "Epoch 00049: val_loss improved from 7657949.00000 to 7639372.00000, saving model to Weights-049--7639372.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14347486.0000 - mean_absolute_error: 14347486.0000 - val_loss: 7639372.0000 - val_mean_absolute_error: 7639372.0000\n",
            "Epoch 50/500\n",
            "13/20 [==================>...........] - ETA: 0s - loss: 15116681.0000 - mean_absolute_error: 15116681.0000\n",
            "Epoch 00050: val_loss did not improve from 7639372.00000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14323218.0000 - mean_absolute_error: 14323218.0000 - val_loss: 7701725.5000 - val_mean_absolute_error: 7701725.5000\n",
            "Epoch 51/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14140057.0000 - mean_absolute_error: 14140057.0000\n",
            "Epoch 00051: val_loss did not improve from 7639372.00000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14299419.0000 - mean_absolute_error: 14299419.0000 - val_loss: 7646131.0000 - val_mean_absolute_error: 7646131.0000\n",
            "Epoch 52/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14086609.0000 - mean_absolute_error: 14086609.0000\n",
            "Epoch 00052: val_loss did not improve from 7639372.00000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14266125.0000 - mean_absolute_error: 14266125.0000 - val_loss: 7666196.0000 - val_mean_absolute_error: 7666196.0000\n",
            "Epoch 53/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14043492.0000 - mean_absolute_error: 14043492.0000\n",
            "Epoch 00053: val_loss improved from 7639372.00000 to 7630262.50000, saving model to Weights-053--7630262.50000.hdf5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14270075.0000 - mean_absolute_error: 14270075.0000 - val_loss: 7630262.5000 - val_mean_absolute_error: 7630262.5000\n",
            "Epoch 54/500\n",
            "13/20 [==================>...........] - ETA: 0s - loss: 14186534.0000 - mean_absolute_error: 14186534.0000\n",
            "Epoch 00054: val_loss did not improve from 7630262.50000\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14226192.0000 - mean_absolute_error: 14226192.0000 - val_loss: 7699121.5000 - val_mean_absolute_error: 7699121.5000\n",
            "Epoch 55/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14189582.0000 - mean_absolute_error: 14189582.0000\n",
            "Epoch 00055: val_loss improved from 7630262.50000 to 7600943.00000, saving model to Weights-055--7600943.00000.hdf5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 14191102.0000 - mean_absolute_error: 14191102.0000 - val_loss: 7600943.0000 - val_mean_absolute_error: 7600943.0000\n",
            "Epoch 56/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14692156.0000 - mean_absolute_error: 14692156.0000\n",
            "Epoch 00056: val_loss did not improve from 7600943.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14168690.0000 - mean_absolute_error: 14168690.0000 - val_loss: 7635398.5000 - val_mean_absolute_error: 7635398.5000\n",
            "Epoch 57/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14091305.0000 - mean_absolute_error: 14091305.0000\n",
            "Epoch 00057: val_loss improved from 7600943.00000 to 7555913.50000, saving model to Weights-057--7555913.50000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14170384.0000 - mean_absolute_error: 14170384.0000 - val_loss: 7555913.5000 - val_mean_absolute_error: 7555913.5000\n",
            "Epoch 58/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14592419.0000 - mean_absolute_error: 14592419.0000\n",
            "Epoch 00058: val_loss did not improve from 7555913.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14127936.0000 - mean_absolute_error: 14127936.0000 - val_loss: 7601917.0000 - val_mean_absolute_error: 7601917.0000\n",
            "Epoch 59/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14339972.0000 - mean_absolute_error: 14339972.0000\n",
            "Epoch 00059: val_loss did not improve from 7555913.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14113005.0000 - mean_absolute_error: 14113005.0000 - val_loss: 7619719.0000 - val_mean_absolute_error: 7619719.0000\n",
            "Epoch 60/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13852076.0000 - mean_absolute_error: 13852076.0000\n",
            "Epoch 00060: val_loss improved from 7555913.50000 to 7516944.00000, saving model to Weights-060--7516944.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14084040.0000 - mean_absolute_error: 14084040.0000 - val_loss: 7516944.0000 - val_mean_absolute_error: 7516944.0000\n",
            "Epoch 61/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14066098.0000 - mean_absolute_error: 14066098.0000\n",
            "Epoch 00061: val_loss did not improve from 7516944.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14066098.0000 - mean_absolute_error: 14066098.0000 - val_loss: 7536488.0000 - val_mean_absolute_error: 7536488.0000\n",
            "Epoch 62/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14294508.0000 - mean_absolute_error: 14294508.0000\n",
            "Epoch 00062: val_loss did not improve from 7516944.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14078147.0000 - mean_absolute_error: 14078147.0000 - val_loss: 7530958.5000 - val_mean_absolute_error: 7530958.5000\n",
            "Epoch 63/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13915943.0000 - mean_absolute_error: 13915943.0000\n",
            "Epoch 00063: val_loss improved from 7516944.00000 to 7490320.00000, saving model to Weights-063--7490320.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14038557.0000 - mean_absolute_error: 14038557.0000 - val_loss: 7490320.0000 - val_mean_absolute_error: 7490320.0000\n",
            "Epoch 64/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13971070.0000 - mean_absolute_error: 13971070.0000\n",
            "Epoch 00064: val_loss did not improve from 7490320.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14084013.0000 - mean_absolute_error: 14084013.0000 - val_loss: 7532845.0000 - val_mean_absolute_error: 7532845.0000\n",
            "Epoch 65/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 14077930.0000 - mean_absolute_error: 14077930.0000\n",
            "Epoch 00065: val_loss improved from 7490320.00000 to 7479903.00000, saving model to Weights-065--7479903.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14077930.0000 - mean_absolute_error: 14077930.0000 - val_loss: 7479903.0000 - val_mean_absolute_error: 7479903.0000\n",
            "Epoch 66/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13859629.0000 - mean_absolute_error: 13859629.0000\n",
            "Epoch 00066: val_loss did not improve from 7479903.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14000395.0000 - mean_absolute_error: 14000395.0000 - val_loss: 7501121.0000 - val_mean_absolute_error: 7501121.0000\n",
            "Epoch 67/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13840569.0000 - mean_absolute_error: 13840569.0000\n",
            "Epoch 00067: val_loss did not improve from 7479903.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 14002800.0000 - mean_absolute_error: 14002800.0000 - val_loss: 7525971.0000 - val_mean_absolute_error: 7525971.0000\n",
            "Epoch 68/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13684722.0000 - mean_absolute_error: 13684722.0000\n",
            "Epoch 00068: val_loss improved from 7479903.00000 to 7473950.50000, saving model to Weights-068--7473950.50000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13997064.0000 - mean_absolute_error: 13997064.0000 - val_loss: 7473950.5000 - val_mean_absolute_error: 7473950.5000\n",
            "Epoch 69/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14002283.0000 - mean_absolute_error: 14002283.0000\n",
            "Epoch 00069: val_loss improved from 7473950.50000 to 7465299.00000, saving model to Weights-069--7465299.00000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 14018925.0000 - mean_absolute_error: 14018925.0000 - val_loss: 7465299.0000 - val_mean_absolute_error: 7465299.0000\n",
            "Epoch 70/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13991307.0000 - mean_absolute_error: 13991307.0000\n",
            "Epoch 00070: val_loss did not improve from 7465299.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13991307.0000 - mean_absolute_error: 13991307.0000 - val_loss: 7503345.0000 - val_mean_absolute_error: 7503345.0000\n",
            "Epoch 71/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13677337.0000 - mean_absolute_error: 13677337.0000\n",
            "Epoch 00071: val_loss did not improve from 7465299.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13962786.0000 - mean_absolute_error: 13962786.0000 - val_loss: 7471237.0000 - val_mean_absolute_error: 7471237.0000\n",
            "Epoch 72/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13956120.0000 - mean_absolute_error: 13956120.0000\n",
            "Epoch 00072: val_loss did not improve from 7465299.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13964627.0000 - mean_absolute_error: 13964627.0000 - val_loss: 7488102.5000 - val_mean_absolute_error: 7488102.5000\n",
            "Epoch 73/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13940008.0000 - mean_absolute_error: 13940008.0000\n",
            "Epoch 00073: val_loss did not improve from 7465299.00000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13996506.0000 - mean_absolute_error: 13996506.0000 - val_loss: 7576355.0000 - val_mean_absolute_error: 7576355.0000\n",
            "Epoch 74/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14106483.0000 - mean_absolute_error: 14106483.0000\n",
            "Epoch 00074: val_loss improved from 7465299.00000 to 7454258.50000, saving model to Weights-074--7454258.50000.hdf5\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13941328.0000 - mean_absolute_error: 13941328.0000 - val_loss: 7454258.5000 - val_mean_absolute_error: 7454258.5000\n",
            "Epoch 75/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13942383.0000 - mean_absolute_error: 13942383.0000\n",
            "Epoch 00075: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13951062.0000 - mean_absolute_error: 13951062.0000 - val_loss: 7460489.0000 - val_mean_absolute_error: 7460489.0000\n",
            "Epoch 76/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13937334.0000 - mean_absolute_error: 13937334.0000\n",
            "Epoch 00076: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13937334.0000 - mean_absolute_error: 13937334.0000 - val_loss: 7459449.0000 - val_mean_absolute_error: 7459449.0000\n",
            "Epoch 77/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13938162.0000 - mean_absolute_error: 13938162.0000\n",
            "Epoch 00077: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13938162.0000 - mean_absolute_error: 13938162.0000 - val_loss: 7465835.0000 - val_mean_absolute_error: 7465835.0000\n",
            "Epoch 78/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13979738.0000 - mean_absolute_error: 13979738.0000\n",
            "Epoch 00078: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13930989.0000 - mean_absolute_error: 13930989.0000 - val_loss: 7458093.5000 - val_mean_absolute_error: 7458093.5000\n",
            "Epoch 79/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14013683.0000 - mean_absolute_error: 14013683.0000\n",
            "Epoch 00079: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13944600.0000 - mean_absolute_error: 13944600.0000 - val_loss: 7502803.0000 - val_mean_absolute_error: 7502803.0000\n",
            "Epoch 80/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13930597.0000 - mean_absolute_error: 13930597.0000\n",
            "Epoch 00080: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13930597.0000 - mean_absolute_error: 13930597.0000 - val_loss: 7465561.5000 - val_mean_absolute_error: 7465561.5000\n",
            "Epoch 81/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13842278.0000 - mean_absolute_error: 13842278.0000\n",
            "Epoch 00081: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13926997.0000 - mean_absolute_error: 13926997.0000 - val_loss: 7456402.5000 - val_mean_absolute_error: 7456402.5000\n",
            "Epoch 82/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14043804.0000 - mean_absolute_error: 14043804.0000\n",
            "Epoch 00082: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13941154.0000 - mean_absolute_error: 13941154.0000 - val_loss: 7487765.5000 - val_mean_absolute_error: 7487765.5000\n",
            "Epoch 83/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13927408.0000 - mean_absolute_error: 13927408.0000\n",
            "Epoch 00083: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13927408.0000 - mean_absolute_error: 13927408.0000 - val_loss: 7480881.5000 - val_mean_absolute_error: 7480881.5000\n",
            "Epoch 84/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13568187.0000 - mean_absolute_error: 13568187.0000\n",
            "Epoch 00084: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13933130.0000 - mean_absolute_error: 13933130.0000 - val_loss: 7474793.5000 - val_mean_absolute_error: 7474793.5000\n",
            "Epoch 85/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13895432.0000 - mean_absolute_error: 13895432.0000\n",
            "Epoch 00085: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13923587.0000 - mean_absolute_error: 13923587.0000 - val_loss: 7474552.0000 - val_mean_absolute_error: 7474552.0000\n",
            "Epoch 86/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13941410.0000 - mean_absolute_error: 13941410.0000\n",
            "Epoch 00086: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13941410.0000 - mean_absolute_error: 13941410.0000 - val_loss: 7482442.5000 - val_mean_absolute_error: 7482442.5000\n",
            "Epoch 87/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13979427.0000 - mean_absolute_error: 13979427.0000\n",
            "Epoch 00087: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13914350.0000 - mean_absolute_error: 13914350.0000 - val_loss: 7477040.0000 - val_mean_absolute_error: 7477040.0000\n",
            "Epoch 88/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13931778.0000 - mean_absolute_error: 13931778.0000\n",
            "Epoch 00088: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13931778.0000 - mean_absolute_error: 13931778.0000 - val_loss: 7464128.0000 - val_mean_absolute_error: 7464128.0000\n",
            "Epoch 89/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13678717.0000 - mean_absolute_error: 13678717.0000\n",
            "Epoch 00089: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13912310.0000 - mean_absolute_error: 13912310.0000 - val_loss: 7466457.5000 - val_mean_absolute_error: 7466457.5000\n",
            "Epoch 90/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13679924.0000 - mean_absolute_error: 13679924.0000\n",
            "Epoch 00090: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13919869.0000 - mean_absolute_error: 13919869.0000 - val_loss: 7527190.5000 - val_mean_absolute_error: 7527190.5000\n",
            "Epoch 91/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13944328.0000 - mean_absolute_error: 13944328.0000\n",
            "Epoch 00091: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13944328.0000 - mean_absolute_error: 13944328.0000 - val_loss: 7486382.5000 - val_mean_absolute_error: 7486382.5000\n",
            "Epoch 92/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13911898.0000 - mean_absolute_error: 13911898.0000\n",
            "Epoch 00092: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13911898.0000 - mean_absolute_error: 13911898.0000 - val_loss: 7511705.0000 - val_mean_absolute_error: 7511705.0000\n",
            "Epoch 93/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13644448.0000 - mean_absolute_error: 13644448.0000\n",
            "Epoch 00093: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13903987.0000 - mean_absolute_error: 13903987.0000 - val_loss: 7471509.0000 - val_mean_absolute_error: 7471509.0000\n",
            "Epoch 94/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13923438.0000 - mean_absolute_error: 13923438.0000\n",
            "Epoch 00094: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13923438.0000 - mean_absolute_error: 13923438.0000 - val_loss: 7482054.5000 - val_mean_absolute_error: 7482054.5000\n",
            "Epoch 95/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13907746.0000 - mean_absolute_error: 13907746.0000\n",
            "Epoch 00095: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13907746.0000 - mean_absolute_error: 13907746.0000 - val_loss: 7500716.0000 - val_mean_absolute_error: 7500716.0000\n",
            "Epoch 96/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13903392.0000 - mean_absolute_error: 13903392.0000\n",
            "Epoch 00096: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13903392.0000 - mean_absolute_error: 13903392.0000 - val_loss: 7496081.5000 - val_mean_absolute_error: 7496081.5000\n",
            "Epoch 97/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14244771.0000 - mean_absolute_error: 14244771.0000\n",
            "Epoch 00097: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13906106.0000 - mean_absolute_error: 13906106.0000 - val_loss: 7480161.5000 - val_mean_absolute_error: 7480161.5000\n",
            "Epoch 98/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13914008.0000 - mean_absolute_error: 13914008.0000\n",
            "Epoch 00098: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13914008.0000 - mean_absolute_error: 13914008.0000 - val_loss: 7518630.5000 - val_mean_absolute_error: 7518630.5000\n",
            "Epoch 99/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13923824.0000 - mean_absolute_error: 13923824.0000\n",
            "Epoch 00099: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13923824.0000 - mean_absolute_error: 13923824.0000 - val_loss: 7467618.5000 - val_mean_absolute_error: 7467618.5000\n",
            "Epoch 100/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13933741.0000 - mean_absolute_error: 13933741.0000\n",
            "Epoch 00100: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13906144.0000 - mean_absolute_error: 13906144.0000 - val_loss: 7481123.0000 - val_mean_absolute_error: 7481123.0000\n",
            "Epoch 101/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13271895.0000 - mean_absolute_error: 13271895.0000\n",
            "Epoch 00101: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13961466.0000 - mean_absolute_error: 13961466.0000 - val_loss: 7462786.5000 - val_mean_absolute_error: 7462786.5000\n",
            "Epoch 102/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14053737.0000 - mean_absolute_error: 14053737.0000\n",
            "Epoch 00102: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13892411.0000 - mean_absolute_error: 13892411.0000 - val_loss: 7547625.0000 - val_mean_absolute_error: 7547625.0000\n",
            "Epoch 103/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14141432.0000 - mean_absolute_error: 14141432.0000\n",
            "Epoch 00103: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13897587.0000 - mean_absolute_error: 13897587.0000 - val_loss: 7486221.0000 - val_mean_absolute_error: 7486221.0000\n",
            "Epoch 104/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13737213.0000 - mean_absolute_error: 13737213.0000\n",
            "Epoch 00104: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13900333.0000 - mean_absolute_error: 13900333.0000 - val_loss: 7467792.0000 - val_mean_absolute_error: 7467792.0000\n",
            "Epoch 105/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13607467.0000 - mean_absolute_error: 13607467.0000\n",
            "Epoch 00105: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13893984.0000 - mean_absolute_error: 13893984.0000 - val_loss: 7488371.0000 - val_mean_absolute_error: 7488371.0000\n",
            "Epoch 106/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14082331.0000 - mean_absolute_error: 14082331.0000\n",
            "Epoch 00106: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13891142.0000 - mean_absolute_error: 13891142.0000 - val_loss: 7481298.5000 - val_mean_absolute_error: 7481298.5000\n",
            "Epoch 107/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13498572.0000 - mean_absolute_error: 13498572.0000\n",
            "Epoch 00107: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13913765.0000 - mean_absolute_error: 13913765.0000 - val_loss: 7481618.5000 - val_mean_absolute_error: 7481618.5000\n",
            "Epoch 108/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 14904000.0000 - mean_absolute_error: 14904000.0000\n",
            "Epoch 00108: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13903683.0000 - mean_absolute_error: 13903683.0000 - val_loss: 7505427.0000 - val_mean_absolute_error: 7505427.0000\n",
            "Epoch 109/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13791520.0000 - mean_absolute_error: 13791520.0000\n",
            "Epoch 00109: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13896458.0000 - mean_absolute_error: 13896458.0000 - val_loss: 7491847.0000 - val_mean_absolute_error: 7491847.0000\n",
            "Epoch 110/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13596195.0000 - mean_absolute_error: 13596195.0000\n",
            "Epoch 00110: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13902173.0000 - mean_absolute_error: 13902173.0000 - val_loss: 7488569.5000 - val_mean_absolute_error: 7488569.5000\n",
            "Epoch 111/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13885725.0000 - mean_absolute_error: 13885725.0000\n",
            "Epoch 00111: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13885725.0000 - mean_absolute_error: 13885725.0000 - val_loss: 7509431.0000 - val_mean_absolute_error: 7509431.0000\n",
            "Epoch 112/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13894237.0000 - mean_absolute_error: 13894237.0000\n",
            "Epoch 00112: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13894237.0000 - mean_absolute_error: 13894237.0000 - val_loss: 7497236.0000 - val_mean_absolute_error: 7497236.0000\n",
            "Epoch 113/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13894331.0000 - mean_absolute_error: 13894331.0000\n",
            "Epoch 00113: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13894331.0000 - mean_absolute_error: 13894331.0000 - val_loss: 7498053.5000 - val_mean_absolute_error: 7498053.5000\n",
            "Epoch 114/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 13968706.0000 - mean_absolute_error: 13968706.0000\n",
            "Epoch 00114: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13904635.0000 - mean_absolute_error: 13904635.0000 - val_loss: 7476511.0000 - val_mean_absolute_error: 7476511.0000\n",
            "Epoch 115/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14148972.0000 - mean_absolute_error: 14148972.0000\n",
            "Epoch 00115: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13890789.0000 - mean_absolute_error: 13890789.0000 - val_loss: 7493936.0000 - val_mean_absolute_error: 7493936.0000\n",
            "Epoch 116/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13882112.0000 - mean_absolute_error: 13882112.0000\n",
            "Epoch 00116: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13882112.0000 - mean_absolute_error: 13882112.0000 - val_loss: 7512533.5000 - val_mean_absolute_error: 7512533.5000\n",
            "Epoch 117/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13894298.0000 - mean_absolute_error: 13894298.0000\n",
            "Epoch 00117: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13925898.0000 - mean_absolute_error: 13925898.0000 - val_loss: 7483309.5000 - val_mean_absolute_error: 7483309.5000\n",
            "Epoch 118/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13299895.0000 - mean_absolute_error: 13299895.0000\n",
            "Epoch 00118: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13870046.0000 - mean_absolute_error: 13870046.0000 - val_loss: 7519033.5000 - val_mean_absolute_error: 7519033.5000\n",
            "Epoch 119/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13893356.0000 - mean_absolute_error: 13893356.0000\n",
            "Epoch 00119: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13891594.0000 - mean_absolute_error: 13891594.0000 - val_loss: 7489739.0000 - val_mean_absolute_error: 7489739.0000\n",
            "Epoch 120/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13824577.0000 - mean_absolute_error: 13824577.0000\n",
            "Epoch 00120: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13898594.0000 - mean_absolute_error: 13898594.0000 - val_loss: 7490269.0000 - val_mean_absolute_error: 7490269.0000\n",
            "Epoch 121/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14153665.0000 - mean_absolute_error: 14153665.0000\n",
            "Epoch 00121: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13878454.0000 - mean_absolute_error: 13878454.0000 - val_loss: 7526737.0000 - val_mean_absolute_error: 7526737.0000\n",
            "Epoch 122/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13837432.0000 - mean_absolute_error: 13837432.0000\n",
            "Epoch 00122: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13912674.0000 - mean_absolute_error: 13912674.0000 - val_loss: 7486772.0000 - val_mean_absolute_error: 7486772.0000\n",
            "Epoch 123/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 13682714.0000 - mean_absolute_error: 13682714.0000\n",
            "Epoch 00123: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13893840.0000 - mean_absolute_error: 13893840.0000 - val_loss: 7526541.5000 - val_mean_absolute_error: 7526541.5000\n",
            "Epoch 124/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14113130.0000 - mean_absolute_error: 14113130.0000\n",
            "Epoch 00124: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13889746.0000 - mean_absolute_error: 13889746.0000 - val_loss: 7484339.0000 - val_mean_absolute_error: 7484339.0000\n",
            "Epoch 125/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14587075.0000 - mean_absolute_error: 14587075.0000\n",
            "Epoch 00125: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13880232.0000 - mean_absolute_error: 13880232.0000 - val_loss: 7541477.5000 - val_mean_absolute_error: 7541477.5000\n",
            "Epoch 126/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13961113.0000 - mean_absolute_error: 13961113.0000\n",
            "Epoch 00126: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13876603.0000 - mean_absolute_error: 13876603.0000 - val_loss: 7495947.0000 - val_mean_absolute_error: 7495947.0000\n",
            "Epoch 127/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13908336.0000 - mean_absolute_error: 13908336.0000\n",
            "Epoch 00127: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13908336.0000 - mean_absolute_error: 13908336.0000 - val_loss: 7477464.0000 - val_mean_absolute_error: 7477464.0000\n",
            "Epoch 128/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14009561.0000 - mean_absolute_error: 14009561.0000\n",
            "Epoch 00128: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13882099.0000 - mean_absolute_error: 13882099.0000 - val_loss: 7504325.5000 - val_mean_absolute_error: 7504325.5000\n",
            "Epoch 129/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14144359.0000 - mean_absolute_error: 14144359.0000\n",
            "Epoch 00129: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13893915.0000 - mean_absolute_error: 13893915.0000 - val_loss: 7506207.0000 - val_mean_absolute_error: 7506207.0000\n",
            "Epoch 130/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13870149.0000 - mean_absolute_error: 13870149.0000\n",
            "Epoch 00130: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13870149.0000 - mean_absolute_error: 13870149.0000 - val_loss: 7502705.0000 - val_mean_absolute_error: 7502705.0000\n",
            "Epoch 131/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13723453.0000 - mean_absolute_error: 13723453.0000\n",
            "Epoch 00131: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13885016.0000 - mean_absolute_error: 13885016.0000 - val_loss: 7484033.0000 - val_mean_absolute_error: 7484033.0000\n",
            "Epoch 132/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13879622.0000 - mean_absolute_error: 13879622.0000\n",
            "Epoch 00132: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13879622.0000 - mean_absolute_error: 13879622.0000 - val_loss: 7504941.0000 - val_mean_absolute_error: 7504941.0000\n",
            "Epoch 133/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13882074.0000 - mean_absolute_error: 13882074.0000\n",
            "Epoch 00133: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13882074.0000 - mean_absolute_error: 13882074.0000 - val_loss: 7502691.0000 - val_mean_absolute_error: 7502691.0000\n",
            "Epoch 134/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13909238.0000 - mean_absolute_error: 13909238.0000\n",
            "Epoch 00134: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13909238.0000 - mean_absolute_error: 13909238.0000 - val_loss: 7466236.0000 - val_mean_absolute_error: 7466236.0000\n",
            "Epoch 135/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13586085.0000 - mean_absolute_error: 13586085.0000\n",
            "Epoch 00135: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13869534.0000 - mean_absolute_error: 13869534.0000 - val_loss: 7565472.0000 - val_mean_absolute_error: 7565472.0000\n",
            "Epoch 136/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13983071.0000 - mean_absolute_error: 13983071.0000\n",
            "Epoch 00136: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13875579.0000 - mean_absolute_error: 13875579.0000 - val_loss: 7506857.0000 - val_mean_absolute_error: 7506857.0000\n",
            "Epoch 137/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13872390.0000 - mean_absolute_error: 13872390.0000\n",
            "Epoch 00137: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13872390.0000 - mean_absolute_error: 13872390.0000 - val_loss: 7497547.0000 - val_mean_absolute_error: 7497547.0000\n",
            "Epoch 138/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13903038.0000 - mean_absolute_error: 13903038.0000\n",
            "Epoch 00138: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13903038.0000 - mean_absolute_error: 13903038.0000 - val_loss: 7467486.5000 - val_mean_absolute_error: 7467486.5000\n",
            "Epoch 139/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13868638.0000 - mean_absolute_error: 13868638.0000\n",
            "Epoch 00139: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13868638.0000 - mean_absolute_error: 13868638.0000 - val_loss: 7550602.5000 - val_mean_absolute_error: 7550602.5000\n",
            "Epoch 140/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13897502.0000 - mean_absolute_error: 13897502.0000\n",
            "Epoch 00140: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13897502.0000 - mean_absolute_error: 13897502.0000 - val_loss: 7477909.0000 - val_mean_absolute_error: 7477909.0000\n",
            "Epoch 141/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13998718.0000 - mean_absolute_error: 13998718.0000\n",
            "Epoch 00141: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13867661.0000 - mean_absolute_error: 13867661.0000 - val_loss: 7520657.5000 - val_mean_absolute_error: 7520657.5000\n",
            "Epoch 142/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13772521.0000 - mean_absolute_error: 13772521.0000\n",
            "Epoch 00142: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13873698.0000 - mean_absolute_error: 13873698.0000 - val_loss: 7505981.0000 - val_mean_absolute_error: 7505981.0000\n",
            "Epoch 143/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13866280.0000 - mean_absolute_error: 13866280.0000\n",
            "Epoch 00143: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13866280.0000 - mean_absolute_error: 13866280.0000 - val_loss: 7491104.0000 - val_mean_absolute_error: 7491104.0000\n",
            "Epoch 144/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14038354.0000 - mean_absolute_error: 14038354.0000\n",
            "Epoch 00144: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13924555.0000 - mean_absolute_error: 13924555.0000 - val_loss: 7533117.5000 - val_mean_absolute_error: 7533117.5000\n",
            "Epoch 145/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14041306.0000 - mean_absolute_error: 14041306.0000\n",
            "Epoch 00145: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13904565.0000 - mean_absolute_error: 13904565.0000 - val_loss: 7470052.0000 - val_mean_absolute_error: 7470052.0000\n",
            "Epoch 146/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14159515.0000 - mean_absolute_error: 14159515.0000\n",
            "Epoch 00146: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13889922.0000 - mean_absolute_error: 13889922.0000 - val_loss: 7545057.0000 - val_mean_absolute_error: 7545057.0000\n",
            "Epoch 147/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13798197.0000 - mean_absolute_error: 13798197.0000\n",
            "Epoch 00147: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13878944.0000 - mean_absolute_error: 13878944.0000 - val_loss: 7491853.0000 - val_mean_absolute_error: 7491853.0000\n",
            "Epoch 148/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13743736.0000 - mean_absolute_error: 13743736.0000\n",
            "Epoch 00148: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13903003.0000 - mean_absolute_error: 13903003.0000 - val_loss: 7536192.0000 - val_mean_absolute_error: 7536192.0000\n",
            "Epoch 149/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14035016.0000 - mean_absolute_error: 14035016.0000\n",
            "Epoch 00149: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13849805.0000 - mean_absolute_error: 13849805.0000 - val_loss: 7496653.5000 - val_mean_absolute_error: 7496653.5000\n",
            "Epoch 150/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13891501.0000 - mean_absolute_error: 13891501.0000\n",
            "Epoch 00150: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13891501.0000 - mean_absolute_error: 13891501.0000 - val_loss: 7479507.0000 - val_mean_absolute_error: 7479507.0000\n",
            "Epoch 151/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13879734.0000 - mean_absolute_error: 13879734.0000\n",
            "Epoch 00151: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13879734.0000 - mean_absolute_error: 13879734.0000 - val_loss: 7514757.5000 - val_mean_absolute_error: 7514757.5000\n",
            "Epoch 152/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13860699.0000 - mean_absolute_error: 13860699.0000\n",
            "Epoch 00152: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13860699.0000 - mean_absolute_error: 13860699.0000 - val_loss: 7518585.5000 - val_mean_absolute_error: 7518585.5000\n",
            "Epoch 153/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13758130.0000 - mean_absolute_error: 13758130.0000\n",
            "Epoch 00153: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13864026.0000 - mean_absolute_error: 13864026.0000 - val_loss: 7521745.0000 - val_mean_absolute_error: 7521745.0000\n",
            "Epoch 154/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13976353.0000 - mean_absolute_error: 13976353.0000\n",
            "Epoch 00154: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13870155.0000 - mean_absolute_error: 13870155.0000 - val_loss: 7490734.5000 - val_mean_absolute_error: 7490734.5000\n",
            "Epoch 155/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13860850.0000 - mean_absolute_error: 13860850.0000\n",
            "Epoch 00155: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13860850.0000 - mean_absolute_error: 13860850.0000 - val_loss: 7509305.5000 - val_mean_absolute_error: 7509305.5000\n",
            "Epoch 156/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13922573.0000 - mean_absolute_error: 13922573.0000\n",
            "Epoch 00156: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13872461.0000 - mean_absolute_error: 13872461.0000 - val_loss: 7511613.0000 - val_mean_absolute_error: 7511613.0000\n",
            "Epoch 157/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13733950.0000 - mean_absolute_error: 13733950.0000\n",
            "Epoch 00157: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13854600.0000 - mean_absolute_error: 13854600.0000 - val_loss: 7507872.0000 - val_mean_absolute_error: 7507872.0000\n",
            "Epoch 158/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13930984.0000 - mean_absolute_error: 13930984.0000\n",
            "Epoch 00158: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13856307.0000 - mean_absolute_error: 13856307.0000 - val_loss: 7523761.5000 - val_mean_absolute_error: 7523761.5000\n",
            "Epoch 159/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14132434.0000 - mean_absolute_error: 14132434.0000\n",
            "Epoch 00159: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13856856.0000 - mean_absolute_error: 13856856.0000 - val_loss: 7512910.5000 - val_mean_absolute_error: 7512910.5000\n",
            "Epoch 160/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13876694.0000 - mean_absolute_error: 13876694.0000\n",
            "Epoch 00160: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13857715.0000 - mean_absolute_error: 13857715.0000 - val_loss: 7518171.0000 - val_mean_absolute_error: 7518171.0000\n",
            "Epoch 161/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13802270.0000 - mean_absolute_error: 13802270.0000\n",
            "Epoch 00161: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13868043.0000 - mean_absolute_error: 13868043.0000 - val_loss: 7505673.0000 - val_mean_absolute_error: 7505673.0000\n",
            "Epoch 162/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13865448.0000 - mean_absolute_error: 13865448.0000\n",
            "Epoch 00162: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13875125.0000 - mean_absolute_error: 13875125.0000 - val_loss: 7521203.0000 - val_mean_absolute_error: 7521203.0000\n",
            "Epoch 163/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13701136.0000 - mean_absolute_error: 13701136.0000\n",
            "Epoch 00163: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13864064.0000 - mean_absolute_error: 13864064.0000 - val_loss: 7501192.0000 - val_mean_absolute_error: 7501192.0000\n",
            "Epoch 164/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13565687.0000 - mean_absolute_error: 13565687.0000\n",
            "Epoch 00164: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13863134.0000 - mean_absolute_error: 13863134.0000 - val_loss: 7512616.0000 - val_mean_absolute_error: 7512616.0000\n",
            "Epoch 165/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13608949.0000 - mean_absolute_error: 13608949.0000\n",
            "Epoch 00165: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13857451.0000 - mean_absolute_error: 13857451.0000 - val_loss: 7497837.0000 - val_mean_absolute_error: 7497837.0000\n",
            "Epoch 166/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13945408.0000 - mean_absolute_error: 13945408.0000\n",
            "Epoch 00166: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13889083.0000 - mean_absolute_error: 13889083.0000 - val_loss: 7506403.0000 - val_mean_absolute_error: 7506403.0000\n",
            "Epoch 167/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13758111.0000 - mean_absolute_error: 13758111.0000\n",
            "Epoch 00167: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13871110.0000 - mean_absolute_error: 13871110.0000 - val_loss: 7475862.5000 - val_mean_absolute_error: 7475862.5000\n",
            "Epoch 168/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13732333.0000 - mean_absolute_error: 13732333.0000\n",
            "Epoch 00168: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13849221.0000 - mean_absolute_error: 13849221.0000 - val_loss: 7514977.5000 - val_mean_absolute_error: 7514977.5000\n",
            "Epoch 169/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14323899.0000 - mean_absolute_error: 14323899.0000\n",
            "Epoch 00169: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13878374.0000 - mean_absolute_error: 13878374.0000 - val_loss: 7562846.5000 - val_mean_absolute_error: 7562846.5000\n",
            "Epoch 170/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13607031.0000 - mean_absolute_error: 13607031.0000\n",
            "Epoch 00170: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13873024.0000 - mean_absolute_error: 13873024.0000 - val_loss: 7528561.5000 - val_mean_absolute_error: 7528561.5000\n",
            "Epoch 171/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 14551724.0000 - mean_absolute_error: 14551724.0000\n",
            "Epoch 00171: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13866352.0000 - mean_absolute_error: 13866352.0000 - val_loss: 7513692.0000 - val_mean_absolute_error: 7513692.0000\n",
            "Epoch 172/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14068692.0000 - mean_absolute_error: 14068692.0000\n",
            "Epoch 00172: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13899706.0000 - mean_absolute_error: 13899706.0000 - val_loss: 7484766.5000 - val_mean_absolute_error: 7484766.5000\n",
            "Epoch 173/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14020864.0000 - mean_absolute_error: 14020864.0000\n",
            "Epoch 00173: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13852907.0000 - mean_absolute_error: 13852907.0000 - val_loss: 7529015.0000 - val_mean_absolute_error: 7529015.0000\n",
            "Epoch 174/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 18388306.0000 - mean_absolute_error: 18388306.0000\n",
            "Epoch 00174: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13843747.0000 - mean_absolute_error: 13843747.0000 - val_loss: 7491791.0000 - val_mean_absolute_error: 7491791.0000\n",
            "Epoch 175/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13843622.0000 - mean_absolute_error: 13843622.0000\n",
            "Epoch 00175: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843622.0000 - mean_absolute_error: 13843622.0000 - val_loss: 7497026.5000 - val_mean_absolute_error: 7497026.5000\n",
            "Epoch 176/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13853077.0000 - mean_absolute_error: 13853077.0000\n",
            "Epoch 00176: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13853077.0000 - mean_absolute_error: 13853077.0000 - val_loss: 7493113.0000 - val_mean_absolute_error: 7493113.0000\n",
            "Epoch 177/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13931667.0000 - mean_absolute_error: 13931667.0000\n",
            "Epoch 00177: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13866013.0000 - mean_absolute_error: 13866013.0000 - val_loss: 7519001.5000 - val_mean_absolute_error: 7519001.5000\n",
            "Epoch 178/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14292622.0000 - mean_absolute_error: 14292622.0000\n",
            "Epoch 00178: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13875898.0000 - mean_absolute_error: 13875898.0000 - val_loss: 7482073.5000 - val_mean_absolute_error: 7482073.5000\n",
            "Epoch 179/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13647770.0000 - mean_absolute_error: 13647770.0000\n",
            "Epoch 00179: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13842357.0000 - mean_absolute_error: 13842357.0000 - val_loss: 7529041.0000 - val_mean_absolute_error: 7529041.0000\n",
            "Epoch 180/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 13290462.0000 - mean_absolute_error: 13290462.0000\n",
            "Epoch 00180: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13853766.0000 - mean_absolute_error: 13853766.0000 - val_loss: 7499538.5000 - val_mean_absolute_error: 7499538.5000\n",
            "Epoch 181/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13872322.0000 - mean_absolute_error: 13872322.0000\n",
            "Epoch 00181: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13872322.0000 - mean_absolute_error: 13872322.0000 - val_loss: 7540591.0000 - val_mean_absolute_error: 7540591.0000\n",
            "Epoch 182/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13640908.0000 - mean_absolute_error: 13640908.0000\n",
            "Epoch 00182: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13895122.0000 - mean_absolute_error: 13895122.0000 - val_loss: 7481010.5000 - val_mean_absolute_error: 7481010.5000\n",
            "Epoch 183/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13859629.0000 - mean_absolute_error: 13859629.0000\n",
            "Epoch 00183: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13859629.0000 - mean_absolute_error: 13859629.0000 - val_loss: 7560685.5000 - val_mean_absolute_error: 7560685.5000\n",
            "Epoch 184/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13845155.0000 - mean_absolute_error: 13845155.0000\n",
            "Epoch 00184: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13845155.0000 - mean_absolute_error: 13845155.0000 - val_loss: 7499377.0000 - val_mean_absolute_error: 7499377.0000\n",
            "Epoch 185/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 13523500.0000 - mean_absolute_error: 13523500.0000\n",
            "Epoch 00185: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13857816.0000 - mean_absolute_error: 13857816.0000 - val_loss: 7512620.0000 - val_mean_absolute_error: 7512620.0000\n",
            "Epoch 186/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13870190.0000 - mean_absolute_error: 13870190.0000\n",
            "Epoch 00186: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13870190.0000 - mean_absolute_error: 13870190.0000 - val_loss: 7556111.0000 - val_mean_absolute_error: 7556111.0000\n",
            "Epoch 187/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13841706.0000 - mean_absolute_error: 13841706.0000\n",
            "Epoch 00187: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13841706.0000 - mean_absolute_error: 13841706.0000 - val_loss: 7492317.5000 - val_mean_absolute_error: 7492317.5000\n",
            "Epoch 188/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14025643.0000 - mean_absolute_error: 14025643.0000\n",
            "Epoch 00188: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13846821.0000 - mean_absolute_error: 13846821.0000 - val_loss: 7534242.5000 - val_mean_absolute_error: 7534242.5000\n",
            "Epoch 189/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13850872.0000 - mean_absolute_error: 13850872.0000\n",
            "Epoch 00189: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13850872.0000 - mean_absolute_error: 13850872.0000 - val_loss: 7480417.0000 - val_mean_absolute_error: 7480417.0000\n",
            "Epoch 190/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13868509.0000 - mean_absolute_error: 13868509.0000\n",
            "Epoch 00190: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13868509.0000 - mean_absolute_error: 13868509.0000 - val_loss: 7531009.0000 - val_mean_absolute_error: 7531009.0000\n",
            "Epoch 191/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13733630.0000 - mean_absolute_error: 13733630.0000\n",
            "Epoch 00191: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843043.0000 - mean_absolute_error: 13843043.0000 - val_loss: 7505821.5000 - val_mean_absolute_error: 7505821.5000\n",
            "Epoch 192/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13804415.0000 - mean_absolute_error: 13804415.0000\n",
            "Epoch 00192: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13863304.0000 - mean_absolute_error: 13863304.0000 - val_loss: 7484182.5000 - val_mean_absolute_error: 7484182.5000\n",
            "Epoch 193/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13925055.0000 - mean_absolute_error: 13925055.0000\n",
            "Epoch 00193: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13904334.0000 - mean_absolute_error: 13904334.0000 - val_loss: 7559864.0000 - val_mean_absolute_error: 7559864.0000\n",
            "Epoch 194/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13846359.0000 - mean_absolute_error: 13846359.0000\n",
            "Epoch 00194: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13827563.0000 - mean_absolute_error: 13827563.0000 - val_loss: 7503242.5000 - val_mean_absolute_error: 7503242.5000\n",
            "Epoch 195/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13854515.0000 - mean_absolute_error: 13854515.0000\n",
            "Epoch 00195: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13854515.0000 - mean_absolute_error: 13854515.0000 - val_loss: 7495424.0000 - val_mean_absolute_error: 7495424.0000\n",
            "Epoch 196/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13812701.0000 - mean_absolute_error: 13812701.0000\n",
            "Epoch 00196: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13860915.0000 - mean_absolute_error: 13860915.0000 - val_loss: 7522280.0000 - val_mean_absolute_error: 7522280.0000\n",
            "Epoch 197/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13905927.0000 - mean_absolute_error: 13905927.0000\n",
            "Epoch 00197: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13882518.0000 - mean_absolute_error: 13882518.0000 - val_loss: 7480804.0000 - val_mean_absolute_error: 7480804.0000\n",
            "Epoch 198/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14012306.0000 - mean_absolute_error: 14012306.0000\n",
            "Epoch 00198: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13860106.0000 - mean_absolute_error: 13860106.0000 - val_loss: 7527705.0000 - val_mean_absolute_error: 7527705.0000\n",
            "Epoch 199/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13806979.0000 - mean_absolute_error: 13806979.0000\n",
            "Epoch 00199: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13840285.0000 - mean_absolute_error: 13840285.0000 - val_loss: 7510779.0000 - val_mean_absolute_error: 7510779.0000\n",
            "Epoch 200/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13773484.0000 - mean_absolute_error: 13773484.0000\n",
            "Epoch 00200: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13848390.0000 - mean_absolute_error: 13848390.0000 - val_loss: 7486174.5000 - val_mean_absolute_error: 7486174.5000\n",
            "Epoch 201/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13885288.0000 - mean_absolute_error: 13885288.0000\n",
            "Epoch 00201: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13885288.0000 - mean_absolute_error: 13885288.0000 - val_loss: 7551974.5000 - val_mean_absolute_error: 7551974.5000\n",
            "Epoch 202/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13948733.0000 - mean_absolute_error: 13948733.0000\n",
            "Epoch 00202: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13836538.0000 - mean_absolute_error: 13836538.0000 - val_loss: 7489254.5000 - val_mean_absolute_error: 7489254.5000\n",
            "Epoch 203/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13787484.0000 - mean_absolute_error: 13787484.0000\n",
            "Epoch 00203: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13836074.0000 - mean_absolute_error: 13836074.0000 - val_loss: 7502208.0000 - val_mean_absolute_error: 7502208.0000\n",
            "Epoch 204/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13819620.0000 - mean_absolute_error: 13819620.0000\n",
            "Epoch 00204: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13849571.0000 - mean_absolute_error: 13849571.0000 - val_loss: 7515744.0000 - val_mean_absolute_error: 7515744.0000\n",
            "Epoch 205/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13829288.0000 - mean_absolute_error: 13829288.0000\n",
            "Epoch 00205: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13857710.0000 - mean_absolute_error: 13857710.0000 - val_loss: 7488875.0000 - val_mean_absolute_error: 7488875.0000\n",
            "Epoch 206/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13646064.0000 - mean_absolute_error: 13646064.0000\n",
            "Epoch 00206: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13847578.0000 - mean_absolute_error: 13847578.0000 - val_loss: 7510644.0000 - val_mean_absolute_error: 7510644.0000\n",
            "Epoch 207/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13646432.0000 - mean_absolute_error: 13646432.0000\n",
            "Epoch 00207: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13852794.0000 - mean_absolute_error: 13852794.0000 - val_loss: 7553950.5000 - val_mean_absolute_error: 7553950.5000\n",
            "Epoch 208/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13986808.0000 - mean_absolute_error: 13986808.0000\n",
            "Epoch 00208: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13830243.0000 - mean_absolute_error: 13830243.0000 - val_loss: 7493869.5000 - val_mean_absolute_error: 7493869.5000\n",
            "Epoch 209/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13843395.0000 - mean_absolute_error: 13843395.0000\n",
            "Epoch 00209: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843395.0000 - mean_absolute_error: 13843395.0000 - val_loss: 7513428.0000 - val_mean_absolute_error: 7513428.0000\n",
            "Epoch 210/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14015176.0000 - mean_absolute_error: 14015176.0000\n",
            "Epoch 00210: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13848586.0000 - mean_absolute_error: 13848586.0000 - val_loss: 7500150.5000 - val_mean_absolute_error: 7500150.5000\n",
            "Epoch 211/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13844714.0000 - mean_absolute_error: 13844714.0000\n",
            "Epoch 00211: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13844714.0000 - mean_absolute_error: 13844714.0000 - val_loss: 7482219.0000 - val_mean_absolute_error: 7482219.0000\n",
            "Epoch 212/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13834224.0000 - mean_absolute_error: 13834224.0000\n",
            "Epoch 00212: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13834224.0000 - mean_absolute_error: 13834224.0000 - val_loss: 7514277.5000 - val_mean_absolute_error: 7514277.5000\n",
            "Epoch 213/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 14177890.0000 - mean_absolute_error: 14177890.0000\n",
            "Epoch 00213: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13834970.0000 - mean_absolute_error: 13834970.0000 - val_loss: 7510493.0000 - val_mean_absolute_error: 7510493.0000\n",
            "Epoch 214/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13772860.0000 - mean_absolute_error: 13772860.0000\n",
            "Epoch 00214: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13833006.0000 - mean_absolute_error: 13833006.0000 - val_loss: 7498141.0000 - val_mean_absolute_error: 7498141.0000\n",
            "Epoch 215/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13846285.0000 - mean_absolute_error: 13846285.0000\n",
            "Epoch 00215: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13846285.0000 - mean_absolute_error: 13846285.0000 - val_loss: 7492603.0000 - val_mean_absolute_error: 7492603.0000\n",
            "Epoch 216/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13848355.0000 - mean_absolute_error: 13848355.0000\n",
            "Epoch 00216: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13848355.0000 - mean_absolute_error: 13848355.0000 - val_loss: 7511121.5000 - val_mean_absolute_error: 7511121.5000\n",
            "Epoch 217/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13829067.0000 - mean_absolute_error: 13829067.0000\n",
            "Epoch 00217: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13829067.0000 - mean_absolute_error: 13829067.0000 - val_loss: 7530121.5000 - val_mean_absolute_error: 7530121.5000\n",
            "Epoch 218/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13828459.0000 - mean_absolute_error: 13828459.0000\n",
            "Epoch 00218: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13835747.0000 - mean_absolute_error: 13835747.0000 - val_loss: 7521949.0000 - val_mean_absolute_error: 7521949.0000\n",
            "Epoch 219/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13867773.0000 - mean_absolute_error: 13867773.0000\n",
            "Epoch 00219: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13867773.0000 - mean_absolute_error: 13867773.0000 - val_loss: 7474835.0000 - val_mean_absolute_error: 7474835.0000\n",
            "Epoch 220/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13579529.0000 - mean_absolute_error: 13579529.0000\n",
            "Epoch 00220: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13820840.0000 - mean_absolute_error: 13820840.0000 - val_loss: 7501272.0000 - val_mean_absolute_error: 7501272.0000\n",
            "Epoch 221/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13828576.0000 - mean_absolute_error: 13828576.0000\n",
            "Epoch 00221: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13828576.0000 - mean_absolute_error: 13828576.0000 - val_loss: 7529187.0000 - val_mean_absolute_error: 7529187.0000\n",
            "Epoch 222/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13836146.0000 - mean_absolute_error: 13836146.0000\n",
            "Epoch 00222: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13836146.0000 - mean_absolute_error: 13836146.0000 - val_loss: 7493485.5000 - val_mean_absolute_error: 7493485.5000\n",
            "Epoch 223/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13843664.0000 - mean_absolute_error: 13843664.0000\n",
            "Epoch 00223: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843664.0000 - mean_absolute_error: 13843664.0000 - val_loss: 7522242.5000 - val_mean_absolute_error: 7522242.5000\n",
            "Epoch 224/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13833336.0000 - mean_absolute_error: 13833336.0000\n",
            "Epoch 00224: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13833336.0000 - mean_absolute_error: 13833336.0000 - val_loss: 7489895.0000 - val_mean_absolute_error: 7489895.0000\n",
            "Epoch 225/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13828718.0000 - mean_absolute_error: 13828718.0000\n",
            "Epoch 00225: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13828718.0000 - mean_absolute_error: 13828718.0000 - val_loss: 7487189.0000 - val_mean_absolute_error: 7487189.0000\n",
            "Epoch 226/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13888077.0000 - mean_absolute_error: 13888077.0000\n",
            "Epoch 00226: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13829611.0000 - mean_absolute_error: 13829611.0000 - val_loss: 7498377.5000 - val_mean_absolute_error: 7498377.5000\n",
            "Epoch 227/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13951104.0000 - mean_absolute_error: 13951104.0000\n",
            "Epoch 00227: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13925229.0000 - mean_absolute_error: 13925229.0000 - val_loss: 7571337.0000 - val_mean_absolute_error: 7571337.0000\n",
            "Epoch 228/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13672145.0000 - mean_absolute_error: 13672145.0000\n",
            "Epoch 00228: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13883290.0000 - mean_absolute_error: 13883290.0000 - val_loss: 7474429.0000 - val_mean_absolute_error: 7474429.0000\n",
            "Epoch 229/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13959281.0000 - mean_absolute_error: 13959281.0000\n",
            "Epoch 00229: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13827142.0000 - mean_absolute_error: 13827142.0000 - val_loss: 7546653.0000 - val_mean_absolute_error: 7546653.0000\n",
            "Epoch 230/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13773189.0000 - mean_absolute_error: 13773189.0000\n",
            "Epoch 00230: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13848821.0000 - mean_absolute_error: 13848821.0000 - val_loss: 7506169.5000 - val_mean_absolute_error: 7506169.5000\n",
            "Epoch 231/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13856648.0000 - mean_absolute_error: 13856648.0000\n",
            "Epoch 00231: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13856648.0000 - mean_absolute_error: 13856648.0000 - val_loss: 7507678.5000 - val_mean_absolute_error: 7507678.5000\n",
            "Epoch 232/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13682818.0000 - mean_absolute_error: 13682818.0000\n",
            "Epoch 00232: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13859123.0000 - mean_absolute_error: 13859123.0000 - val_loss: 7503981.0000 - val_mean_absolute_error: 7503981.0000\n",
            "Epoch 233/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13838059.0000 - mean_absolute_error: 13838059.0000\n",
            "Epoch 00233: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13838059.0000 - mean_absolute_error: 13838059.0000 - val_loss: 7541251.0000 - val_mean_absolute_error: 7541251.0000\n",
            "Epoch 234/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13744077.0000 - mean_absolute_error: 13744077.0000\n",
            "Epoch 00234: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13848922.0000 - mean_absolute_error: 13848922.0000 - val_loss: 7491317.5000 - val_mean_absolute_error: 7491317.5000\n",
            "Epoch 235/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13782870.0000 - mean_absolute_error: 13782870.0000\n",
            "Epoch 00235: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13850709.0000 - mean_absolute_error: 13850709.0000 - val_loss: 7546603.0000 - val_mean_absolute_error: 7546603.0000\n",
            "Epoch 236/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13833539.0000 - mean_absolute_error: 13833539.0000\n",
            "Epoch 00236: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13833539.0000 - mean_absolute_error: 13833539.0000 - val_loss: 7498857.0000 - val_mean_absolute_error: 7498857.0000\n",
            "Epoch 237/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 13812738.0000 - mean_absolute_error: 13812738.0000\n",
            "Epoch 00237: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13830928.0000 - mean_absolute_error: 13830928.0000 - val_loss: 7499072.0000 - val_mean_absolute_error: 7499072.0000\n",
            "Epoch 238/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14039852.0000 - mean_absolute_error: 14039852.0000\n",
            "Epoch 00238: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13821870.0000 - mean_absolute_error: 13821870.0000 - val_loss: 7511801.5000 - val_mean_absolute_error: 7511801.5000\n",
            "Epoch 239/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13458058.0000 - mean_absolute_error: 13458058.0000\n",
            "Epoch 00239: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13842526.0000 - mean_absolute_error: 13842526.0000 - val_loss: 7487642.5000 - val_mean_absolute_error: 7487642.5000\n",
            "Epoch 240/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13825813.0000 - mean_absolute_error: 13825813.0000\n",
            "Epoch 00240: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13825813.0000 - mean_absolute_error: 13825813.0000 - val_loss: 7553347.0000 - val_mean_absolute_error: 7553347.0000\n",
            "Epoch 241/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14114647.0000 - mean_absolute_error: 14114647.0000\n",
            "Epoch 00241: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13880354.0000 - mean_absolute_error: 13880354.0000 - val_loss: 7554304.0000 - val_mean_absolute_error: 7554304.0000\n",
            "Epoch 242/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14194444.0000 - mean_absolute_error: 14194444.0000\n",
            "Epoch 00242: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13828934.0000 - mean_absolute_error: 13828934.0000 - val_loss: 7479932.0000 - val_mean_absolute_error: 7479932.0000\n",
            "Epoch 243/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13843053.0000 - mean_absolute_error: 13843053.0000\n",
            "Epoch 00243: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843053.0000 - mean_absolute_error: 13843053.0000 - val_loss: 7525679.0000 - val_mean_absolute_error: 7525679.0000\n",
            "Epoch 244/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14081347.0000 - mean_absolute_error: 14081347.0000\n",
            "Epoch 00244: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13845610.0000 - mean_absolute_error: 13845610.0000 - val_loss: 7546255.0000 - val_mean_absolute_error: 7546255.0000\n",
            "Epoch 245/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13513990.0000 - mean_absolute_error: 13513990.0000\n",
            "Epoch 00245: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13807286.0000 - mean_absolute_error: 13807286.0000 - val_loss: 7494800.0000 - val_mean_absolute_error: 7494800.0000\n",
            "Epoch 246/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13762772.0000 - mean_absolute_error: 13762772.0000\n",
            "Epoch 00246: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13837725.0000 - mean_absolute_error: 13837725.0000 - val_loss: 7487686.5000 - val_mean_absolute_error: 7487686.5000\n",
            "Epoch 247/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14087429.0000 - mean_absolute_error: 14087429.0000\n",
            "Epoch 00247: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13820699.0000 - mean_absolute_error: 13820699.0000 - val_loss: 7513400.0000 - val_mean_absolute_error: 7513400.0000\n",
            "Epoch 248/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13986873.0000 - mean_absolute_error: 13986873.0000\n",
            "Epoch 00248: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13824226.0000 - mean_absolute_error: 13824226.0000 - val_loss: 7535669.5000 - val_mean_absolute_error: 7535669.5000\n",
            "Epoch 249/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13673189.0000 - mean_absolute_error: 13673189.0000\n",
            "Epoch 00249: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13856917.0000 - mean_absolute_error: 13856917.0000 - val_loss: 7479423.0000 - val_mean_absolute_error: 7479423.0000\n",
            "Epoch 250/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13993231.0000 - mean_absolute_error: 13993231.0000\n",
            "Epoch 00250: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13800186.0000 - mean_absolute_error: 13800186.0000 - val_loss: 7541679.0000 - val_mean_absolute_error: 7541679.0000\n",
            "Epoch 251/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13920330.0000 - mean_absolute_error: 13920330.0000\n",
            "Epoch 00251: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13828494.0000 - mean_absolute_error: 13828494.0000 - val_loss: 7534582.5000 - val_mean_absolute_error: 7534582.5000\n",
            "Epoch 252/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13681704.0000 - mean_absolute_error: 13681704.0000\n",
            "Epoch 00252: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13821656.0000 - mean_absolute_error: 13821656.0000 - val_loss: 7517224.0000 - val_mean_absolute_error: 7517224.0000\n",
            "Epoch 253/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13709545.0000 - mean_absolute_error: 13709545.0000\n",
            "Epoch 00253: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13821450.0000 - mean_absolute_error: 13821450.0000 - val_loss: 7488698.5000 - val_mean_absolute_error: 7488698.5000\n",
            "Epoch 254/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13818909.0000 - mean_absolute_error: 13818909.0000\n",
            "Epoch 00254: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13818909.0000 - mean_absolute_error: 13818909.0000 - val_loss: 7506328.0000 - val_mean_absolute_error: 7506328.0000\n",
            "Epoch 255/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13814562.0000 - mean_absolute_error: 13814562.0000\n",
            "Epoch 00255: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814562.0000 - mean_absolute_error: 13814562.0000 - val_loss: 7510288.0000 - val_mean_absolute_error: 7510288.0000\n",
            "Epoch 256/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13476884.0000 - mean_absolute_error: 13476884.0000\n",
            "Epoch 00256: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13816237.0000 - mean_absolute_error: 13816237.0000 - val_loss: 7499152.0000 - val_mean_absolute_error: 7499152.0000\n",
            "Epoch 257/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13839018.0000 - mean_absolute_error: 13839018.0000\n",
            "Epoch 00257: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13839018.0000 - mean_absolute_error: 13839018.0000 - val_loss: 7530699.0000 - val_mean_absolute_error: 7530699.0000\n",
            "Epoch 258/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13846906.0000 - mean_absolute_error: 13846906.0000\n",
            "Epoch 00258: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13846906.0000 - mean_absolute_error: 13846906.0000 - val_loss: 7497482.5000 - val_mean_absolute_error: 7497482.5000\n",
            "Epoch 259/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 17607786.0000 - mean_absolute_error: 17607786.0000\n",
            "Epoch 00259: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13870346.0000 - mean_absolute_error: 13870346.0000 - val_loss: 7565173.5000 - val_mean_absolute_error: 7565173.5000\n",
            "Epoch 260/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14010621.0000 - mean_absolute_error: 14010621.0000\n",
            "Epoch 00260: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13850013.0000 - mean_absolute_error: 13850013.0000 - val_loss: 7502426.5000 - val_mean_absolute_error: 7502426.5000\n",
            "Epoch 261/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13818150.0000 - mean_absolute_error: 13818150.0000\n",
            "Epoch 00261: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13818150.0000 - mean_absolute_error: 13818150.0000 - val_loss: 7516553.5000 - val_mean_absolute_error: 7516553.5000\n",
            "Epoch 262/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 13082770.0000 - mean_absolute_error: 13082770.0000\n",
            "Epoch 00262: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13818621.0000 - mean_absolute_error: 13818621.0000 - val_loss: 7511321.0000 - val_mean_absolute_error: 7511321.0000\n",
            "Epoch 263/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13648607.0000 - mean_absolute_error: 13648607.0000\n",
            "Epoch 00263: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13822368.0000 - mean_absolute_error: 13822368.0000 - val_loss: 7484806.5000 - val_mean_absolute_error: 7484806.5000\n",
            "Epoch 264/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13949435.0000 - mean_absolute_error: 13949435.0000\n",
            "Epoch 00264: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13843266.0000 - mean_absolute_error: 13843266.0000 - val_loss: 7547389.0000 - val_mean_absolute_error: 7547389.0000\n",
            "Epoch 265/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13862451.0000 - mean_absolute_error: 13862451.0000\n",
            "Epoch 00265: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13830221.0000 - mean_absolute_error: 13830221.0000 - val_loss: 7488157.0000 - val_mean_absolute_error: 7488157.0000\n",
            "Epoch 266/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13832920.0000 - mean_absolute_error: 13832920.0000\n",
            "Epoch 00266: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13832920.0000 - mean_absolute_error: 13832920.0000 - val_loss: 7494691.0000 - val_mean_absolute_error: 7494691.0000\n",
            "Epoch 267/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13826448.0000 - mean_absolute_error: 13826448.0000\n",
            "Epoch 00267: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13826448.0000 - mean_absolute_error: 13826448.0000 - val_loss: 7543365.0000 - val_mean_absolute_error: 7543365.0000\n",
            "Epoch 268/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13742307.0000 - mean_absolute_error: 13742307.0000\n",
            "Epoch 00268: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13817822.0000 - mean_absolute_error: 13817822.0000 - val_loss: 7512171.0000 - val_mean_absolute_error: 7512171.0000\n",
            "Epoch 269/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13835696.0000 - mean_absolute_error: 13835696.0000\n",
            "Epoch 00269: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13835696.0000 - mean_absolute_error: 13835696.0000 - val_loss: 7502155.0000 - val_mean_absolute_error: 7502155.0000\n",
            "Epoch 270/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13760760.0000 - mean_absolute_error: 13760760.0000\n",
            "Epoch 00270: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13811101.0000 - mean_absolute_error: 13811101.0000 - val_loss: 7502563.0000 - val_mean_absolute_error: 7502563.0000\n",
            "Epoch 271/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13890285.0000 - mean_absolute_error: 13890285.0000\n",
            "Epoch 00271: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13809848.0000 - mean_absolute_error: 13809848.0000 - val_loss: 7527142.5000 - val_mean_absolute_error: 7527142.5000\n",
            "Epoch 272/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13681718.0000 - mean_absolute_error: 13681718.0000\n",
            "Epoch 00272: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13816680.0000 - mean_absolute_error: 13816680.0000 - val_loss: 7506376.0000 - val_mean_absolute_error: 7506376.0000\n",
            "Epoch 273/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13956051.0000 - mean_absolute_error: 13956051.0000\n",
            "Epoch 00273: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13816115.0000 - mean_absolute_error: 13816115.0000 - val_loss: 7509365.0000 - val_mean_absolute_error: 7509365.0000\n",
            "Epoch 274/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13882199.0000 - mean_absolute_error: 13882199.0000\n",
            "Epoch 00274: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13803790.0000 - mean_absolute_error: 13803790.0000 - val_loss: 7527905.0000 - val_mean_absolute_error: 7527905.0000\n",
            "Epoch 275/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13907524.0000 - mean_absolute_error: 13907524.0000\n",
            "Epoch 00275: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13818194.0000 - mean_absolute_error: 13818194.0000 - val_loss: 7550736.0000 - val_mean_absolute_error: 7550736.0000\n",
            "Epoch 276/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13619249.0000 - mean_absolute_error: 13619249.0000\n",
            "Epoch 00276: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13809498.0000 - mean_absolute_error: 13809498.0000 - val_loss: 7515078.5000 - val_mean_absolute_error: 7515078.5000\n",
            "Epoch 277/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13885699.0000 - mean_absolute_error: 13885699.0000\n",
            "Epoch 00277: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13820000.0000 - mean_absolute_error: 13820000.0000 - val_loss: 7508357.0000 - val_mean_absolute_error: 7508357.0000\n",
            "Epoch 278/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13821646.0000 - mean_absolute_error: 13821646.0000\n",
            "Epoch 00278: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13821646.0000 - mean_absolute_error: 13821646.0000 - val_loss: 7514485.0000 - val_mean_absolute_error: 7514485.0000\n",
            "Epoch 279/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13804726.0000 - mean_absolute_error: 13804726.0000\n",
            "Epoch 00279: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13804726.0000 - mean_absolute_error: 13804726.0000 - val_loss: 7501753.0000 - val_mean_absolute_error: 7501753.0000\n",
            "Epoch 280/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13463016.0000 - mean_absolute_error: 13463016.0000\n",
            "Epoch 00280: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13802670.0000 - mean_absolute_error: 13802670.0000 - val_loss: 7514038.5000 - val_mean_absolute_error: 7514038.5000\n",
            "Epoch 281/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13829848.0000 - mean_absolute_error: 13829848.0000\n",
            "Epoch 00281: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13829848.0000 - mean_absolute_error: 13829848.0000 - val_loss: 7527012.0000 - val_mean_absolute_error: 7527012.0000\n",
            "Epoch 282/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13826835.0000 - mean_absolute_error: 13826835.0000\n",
            "Epoch 00282: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13826835.0000 - mean_absolute_error: 13826835.0000 - val_loss: 7493581.5000 - val_mean_absolute_error: 7493581.5000\n",
            "Epoch 283/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13798666.0000 - mean_absolute_error: 13798666.0000\n",
            "Epoch 00283: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13798666.0000 - mean_absolute_error: 13798666.0000 - val_loss: 7534229.0000 - val_mean_absolute_error: 7534229.0000\n",
            "Epoch 284/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13907524.0000 - mean_absolute_error: 13907524.0000\n",
            "Epoch 00284: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13816387.0000 - mean_absolute_error: 13816387.0000 - val_loss: 7540174.5000 - val_mean_absolute_error: 7540174.5000\n",
            "Epoch 285/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13660567.0000 - mean_absolute_error: 13660567.0000\n",
            "Epoch 00285: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13803051.0000 - mean_absolute_error: 13803051.0000 - val_loss: 7505582.5000 - val_mean_absolute_error: 7505582.5000\n",
            "Epoch 286/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14022436.0000 - mean_absolute_error: 14022436.0000\n",
            "Epoch 00286: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13800821.0000 - mean_absolute_error: 13800821.0000 - val_loss: 7513168.0000 - val_mean_absolute_error: 7513168.0000\n",
            "Epoch 287/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13542544.0000 - mean_absolute_error: 13542544.0000\n",
            "Epoch 00287: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13817819.0000 - mean_absolute_error: 13817819.0000 - val_loss: 7531302.5000 - val_mean_absolute_error: 7531302.5000\n",
            "Epoch 288/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13732502.0000 - mean_absolute_error: 13732502.0000\n",
            "Epoch 00288: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13808333.0000 - mean_absolute_error: 13808333.0000 - val_loss: 7495758.5000 - val_mean_absolute_error: 7495758.5000\n",
            "Epoch 289/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13805546.0000 - mean_absolute_error: 13805546.0000\n",
            "Epoch 00289: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13805546.0000 - mean_absolute_error: 13805546.0000 - val_loss: 7510601.5000 - val_mean_absolute_error: 7510601.5000\n",
            "Epoch 290/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13776602.0000 - mean_absolute_error: 13776602.0000\n",
            "Epoch 00290: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814267.0000 - mean_absolute_error: 13814267.0000 - val_loss: 7526857.0000 - val_mean_absolute_error: 7526857.0000\n",
            "Epoch 291/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13935726.0000 - mean_absolute_error: 13935726.0000\n",
            "Epoch 00291: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13798387.0000 - mean_absolute_error: 13798387.0000 - val_loss: 7505964.0000 - val_mean_absolute_error: 7505964.0000\n",
            "Epoch 292/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13681492.0000 - mean_absolute_error: 13681492.0000\n",
            "Epoch 00292: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13806363.0000 - mean_absolute_error: 13806363.0000 - val_loss: 7509189.5000 - val_mean_absolute_error: 7509189.5000\n",
            "Epoch 293/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 13324589.0000 - mean_absolute_error: 13324589.0000\n",
            "Epoch 00293: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13819184.0000 - mean_absolute_error: 13819184.0000 - val_loss: 7510078.5000 - val_mean_absolute_error: 7510078.5000\n",
            "Epoch 294/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13854610.0000 - mean_absolute_error: 13854610.0000\n",
            "Epoch 00294: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13797398.0000 - mean_absolute_error: 13797398.0000 - val_loss: 7539053.0000 - val_mean_absolute_error: 7539053.0000\n",
            "Epoch 295/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13986466.0000 - mean_absolute_error: 13986466.0000\n",
            "Epoch 00295: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13803872.0000 - mean_absolute_error: 13803872.0000 - val_loss: 7538251.0000 - val_mean_absolute_error: 7538251.0000\n",
            "Epoch 296/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13805565.0000 - mean_absolute_error: 13805565.0000\n",
            "Epoch 00296: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13805565.0000 - mean_absolute_error: 13805565.0000 - val_loss: 7502068.0000 - val_mean_absolute_error: 7502068.0000\n",
            "Epoch 297/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13810819.0000 - mean_absolute_error: 13810819.0000\n",
            "Epoch 00297: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13810819.0000 - mean_absolute_error: 13810819.0000 - val_loss: 7522359.0000 - val_mean_absolute_error: 7522359.0000\n",
            "Epoch 298/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13887539.0000 - mean_absolute_error: 13887539.0000\n",
            "Epoch 00298: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13811480.0000 - mean_absolute_error: 13811480.0000 - val_loss: 7502257.5000 - val_mean_absolute_error: 7502257.5000\n",
            "Epoch 299/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13805843.0000 - mean_absolute_error: 13805843.0000\n",
            "Epoch 00299: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13836578.0000 - mean_absolute_error: 13836578.0000 - val_loss: 7556199.0000 - val_mean_absolute_error: 7556199.0000\n",
            "Epoch 300/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13831482.0000 - mean_absolute_error: 13831482.0000\n",
            "Epoch 00300: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13794154.0000 - mean_absolute_error: 13794154.0000 - val_loss: 7515315.0000 - val_mean_absolute_error: 7515315.0000\n",
            "Epoch 301/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13799102.0000 - mean_absolute_error: 13799102.0000\n",
            "Epoch 00301: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13799102.0000 - mean_absolute_error: 13799102.0000 - val_loss: 7505999.0000 - val_mean_absolute_error: 7505999.0000\n",
            "Epoch 302/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13949725.0000 - mean_absolute_error: 13949725.0000\n",
            "Epoch 00302: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13804181.0000 - mean_absolute_error: 13804181.0000 - val_loss: 7529798.5000 - val_mean_absolute_error: 7529798.5000\n",
            "Epoch 303/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14056500.0000 - mean_absolute_error: 14056500.0000\n",
            "Epoch 00303: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814947.0000 - mean_absolute_error: 13814947.0000 - val_loss: 7557669.0000 - val_mean_absolute_error: 7557669.0000\n",
            "Epoch 304/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13976974.0000 - mean_absolute_error: 13976974.0000\n",
            "Epoch 00304: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13813480.0000 - mean_absolute_error: 13813480.0000 - val_loss: 7529214.5000 - val_mean_absolute_error: 7529214.5000\n",
            "Epoch 305/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 14191293.0000 - mean_absolute_error: 14191293.0000\n",
            "Epoch 00305: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13804624.0000 - mean_absolute_error: 13804624.0000 - val_loss: 7499092.0000 - val_mean_absolute_error: 7499092.0000\n",
            "Epoch 306/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13813708.0000 - mean_absolute_error: 13813708.0000\n",
            "Epoch 00306: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13802046.0000 - mean_absolute_error: 13802046.0000 - val_loss: 7515697.5000 - val_mean_absolute_error: 7515697.5000\n",
            "Epoch 307/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13810245.0000 - mean_absolute_error: 13810245.0000\n",
            "Epoch 00307: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13810245.0000 - mean_absolute_error: 13810245.0000 - val_loss: 7574249.0000 - val_mean_absolute_error: 7574249.0000\n",
            "Epoch 308/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13806230.0000 - mean_absolute_error: 13806230.0000\n",
            "Epoch 00308: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13806230.0000 - mean_absolute_error: 13806230.0000 - val_loss: 7510801.5000 - val_mean_absolute_error: 7510801.5000\n",
            "Epoch 309/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13792717.0000 - mean_absolute_error: 13792717.0000\n",
            "Epoch 00309: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13792717.0000 - mean_absolute_error: 13792717.0000 - val_loss: 7524517.0000 - val_mean_absolute_error: 7524517.0000\n",
            "Epoch 310/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13909985.0000 - mean_absolute_error: 13909985.0000\n",
            "Epoch 00310: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13802957.0000 - mean_absolute_error: 13802957.0000 - val_loss: 7512558.5000 - val_mean_absolute_error: 7512558.5000\n",
            "Epoch 311/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13889053.0000 - mean_absolute_error: 13889053.0000\n",
            "Epoch 00311: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13806102.0000 - mean_absolute_error: 13806102.0000 - val_loss: 7529818.5000 - val_mean_absolute_error: 7529818.5000\n",
            "Epoch 312/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13812795.0000 - mean_absolute_error: 13812795.0000\n",
            "Epoch 00312: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13812795.0000 - mean_absolute_error: 13812795.0000 - val_loss: 7513203.0000 - val_mean_absolute_error: 7513203.0000\n",
            "Epoch 313/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14010830.0000 - mean_absolute_error: 14010830.0000\n",
            "Epoch 00313: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13791547.0000 - mean_absolute_error: 13791547.0000 - val_loss: 7514718.5000 - val_mean_absolute_error: 7514718.5000\n",
            "Epoch 314/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13904765.0000 - mean_absolute_error: 13904765.0000\n",
            "Epoch 00314: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13826970.0000 - mean_absolute_error: 13826970.0000 - val_loss: 7553251.0000 - val_mean_absolute_error: 7553251.0000\n",
            "Epoch 315/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14001242.0000 - mean_absolute_error: 14001242.0000\n",
            "Epoch 00315: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13800306.0000 - mean_absolute_error: 13800306.0000 - val_loss: 7510756.0000 - val_mean_absolute_error: 7510756.0000\n",
            "Epoch 316/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14100840.0000 - mean_absolute_error: 14100840.0000\n",
            "Epoch 00316: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13849902.0000 - mean_absolute_error: 13849902.0000 - val_loss: 7527920.0000 - val_mean_absolute_error: 7527920.0000\n",
            "Epoch 317/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13819365.0000 - mean_absolute_error: 13819365.0000\n",
            "Epoch 00317: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13869646.0000 - mean_absolute_error: 13869646.0000 - val_loss: 7494666.5000 - val_mean_absolute_error: 7494666.5000\n",
            "Epoch 318/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14127264.0000 - mean_absolute_error: 14127264.0000\n",
            "Epoch 00318: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814096.0000 - mean_absolute_error: 13814096.0000 - val_loss: 7563465.5000 - val_mean_absolute_error: 7563465.5000\n",
            "Epoch 319/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13826187.0000 - mean_absolute_error: 13826187.0000\n",
            "Epoch 00319: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13794592.0000 - mean_absolute_error: 13794592.0000 - val_loss: 7516828.0000 - val_mean_absolute_error: 7516828.0000\n",
            "Epoch 320/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13751205.0000 - mean_absolute_error: 13751205.0000\n",
            "Epoch 00320: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13791792.0000 - mean_absolute_error: 13791792.0000 - val_loss: 7514264.0000 - val_mean_absolute_error: 7514264.0000\n",
            "Epoch 321/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13587138.0000 - mean_absolute_error: 13587138.0000\n",
            "Epoch 00321: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13798014.0000 - mean_absolute_error: 13798014.0000 - val_loss: 7546193.5000 - val_mean_absolute_error: 7546193.5000\n",
            "Epoch 322/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 14133631.0000 - mean_absolute_error: 14133631.0000\n",
            "Epoch 00322: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13790858.0000 - mean_absolute_error: 13790858.0000 - val_loss: 7519509.0000 - val_mean_absolute_error: 7519509.0000\n",
            "Epoch 323/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13924951.0000 - mean_absolute_error: 13924951.0000\n",
            "Epoch 00323: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13789594.0000 - mean_absolute_error: 13789594.0000 - val_loss: 7515157.0000 - val_mean_absolute_error: 7515157.0000\n",
            "Epoch 324/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13713032.0000 - mean_absolute_error: 13713032.0000\n",
            "Epoch 00324: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13788944.0000 - mean_absolute_error: 13788944.0000 - val_loss: 7516869.5000 - val_mean_absolute_error: 7516869.5000\n",
            "Epoch 325/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13784187.0000 - mean_absolute_error: 13784187.0000\n",
            "Epoch 00325: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13784187.0000 - mean_absolute_error: 13784187.0000 - val_loss: 7528621.5000 - val_mean_absolute_error: 7528621.5000\n",
            "Epoch 326/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13797587.0000 - mean_absolute_error: 13797587.0000\n",
            "Epoch 00326: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13797587.0000 - mean_absolute_error: 13797587.0000 - val_loss: 7542866.5000 - val_mean_absolute_error: 7542866.5000\n",
            "Epoch 327/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14020875.0000 - mean_absolute_error: 14020875.0000\n",
            "Epoch 00327: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13797440.0000 - mean_absolute_error: 13797440.0000 - val_loss: 7514166.5000 - val_mean_absolute_error: 7514166.5000\n",
            "Epoch 328/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13902701.0000 - mean_absolute_error: 13902701.0000\n",
            "Epoch 00328: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814349.0000 - mean_absolute_error: 13814349.0000 - val_loss: 7534961.5000 - val_mean_absolute_error: 7534961.5000\n",
            "Epoch 329/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13803450.0000 - mean_absolute_error: 13803450.0000\n",
            "Epoch 00329: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13803450.0000 - mean_absolute_error: 13803450.0000 - val_loss: 7533769.5000 - val_mean_absolute_error: 7533769.5000\n",
            "Epoch 330/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13784326.0000 - mean_absolute_error: 13784326.0000\n",
            "Epoch 00330: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13784326.0000 - mean_absolute_error: 13784326.0000 - val_loss: 7522869.5000 - val_mean_absolute_error: 7522869.5000\n",
            "Epoch 331/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13907266.0000 - mean_absolute_error: 13907266.0000\n",
            "Epoch 00331: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13813970.0000 - mean_absolute_error: 13813970.0000 - val_loss: 7544093.0000 - val_mean_absolute_error: 7544093.0000\n",
            "Epoch 332/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13972057.0000 - mean_absolute_error: 13972057.0000\n",
            "Epoch 00332: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13795088.0000 - mean_absolute_error: 13795088.0000 - val_loss: 7511765.0000 - val_mean_absolute_error: 7511765.0000\n",
            "Epoch 333/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13731213.0000 - mean_absolute_error: 13731213.0000\n",
            "Epoch 00333: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13801709.0000 - mean_absolute_error: 13801709.0000 - val_loss: 7540643.0000 - val_mean_absolute_error: 7540643.0000\n",
            "Epoch 334/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13818957.0000 - mean_absolute_error: 13818957.0000\n",
            "Epoch 00334: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13784962.0000 - mean_absolute_error: 13784962.0000 - val_loss: 7512603.0000 - val_mean_absolute_error: 7512603.0000\n",
            "Epoch 335/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13539265.0000 - mean_absolute_error: 13539265.0000\n",
            "Epoch 00335: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13785427.0000 - mean_absolute_error: 13785427.0000 - val_loss: 7520204.0000 - val_mean_absolute_error: 7520204.0000\n",
            "Epoch 336/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 20286224.0000 - mean_absolute_error: 20286224.0000\n",
            "Epoch 00336: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13789344.0000 - mean_absolute_error: 13789344.0000 - val_loss: 7516514.5000 - val_mean_absolute_error: 7516514.5000\n",
            "Epoch 337/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13838870.0000 - mean_absolute_error: 13838870.0000\n",
            "Epoch 00337: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13838870.0000 - mean_absolute_error: 13838870.0000 - val_loss: 7575079.0000 - val_mean_absolute_error: 7575079.0000\n",
            "Epoch 338/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13625618.0000 - mean_absolute_error: 13625618.0000\n",
            "Epoch 00338: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13801176.0000 - mean_absolute_error: 13801176.0000 - val_loss: 7505149.5000 - val_mean_absolute_error: 7505149.5000\n",
            "Epoch 339/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13779611.0000 - mean_absolute_error: 13779611.0000\n",
            "Epoch 00339: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13779611.0000 - mean_absolute_error: 13779611.0000 - val_loss: 7524998.5000 - val_mean_absolute_error: 7524998.5000\n",
            "Epoch 340/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13780283.0000 - mean_absolute_error: 13780283.0000\n",
            "Epoch 00340: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13780283.0000 - mean_absolute_error: 13780283.0000 - val_loss: 7554814.5000 - val_mean_absolute_error: 7554814.5000\n",
            "Epoch 341/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13796912.0000 - mean_absolute_error: 13796912.0000\n",
            "Epoch 00341: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13796912.0000 - mean_absolute_error: 13796912.0000 - val_loss: 7539029.0000 - val_mean_absolute_error: 7539029.0000\n",
            "Epoch 342/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13603378.0000 - mean_absolute_error: 13603378.0000\n",
            "Epoch 00342: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13787936.0000 - mean_absolute_error: 13787936.0000 - val_loss: 7514572.0000 - val_mean_absolute_error: 7514572.0000\n",
            "Epoch 343/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13795695.0000 - mean_absolute_error: 13795695.0000\n",
            "Epoch 00343: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13780450.0000 - mean_absolute_error: 13780450.0000 - val_loss: 7531067.0000 - val_mean_absolute_error: 7531067.0000\n",
            "Epoch 344/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13785827.0000 - mean_absolute_error: 13785827.0000\n",
            "Epoch 00344: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13785827.0000 - mean_absolute_error: 13785827.0000 - val_loss: 7523051.0000 - val_mean_absolute_error: 7523051.0000\n",
            "Epoch 345/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13779186.0000 - mean_absolute_error: 13779186.0000\n",
            "Epoch 00345: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13779186.0000 - mean_absolute_error: 13779186.0000 - val_loss: 7527133.0000 - val_mean_absolute_error: 7527133.0000\n",
            "Epoch 346/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13993852.0000 - mean_absolute_error: 13993852.0000\n",
            "Epoch 00346: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13786413.0000 - mean_absolute_error: 13786413.0000 - val_loss: 7540736.0000 - val_mean_absolute_error: 7540736.0000\n",
            "Epoch 347/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13940663.0000 - mean_absolute_error: 13940663.0000\n",
            "Epoch 00347: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13790451.0000 - mean_absolute_error: 13790451.0000 - val_loss: 7565179.0000 - val_mean_absolute_error: 7565179.0000\n",
            "Epoch 348/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13787611.0000 - mean_absolute_error: 13787611.0000\n",
            "Epoch 00348: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13787611.0000 - mean_absolute_error: 13787611.0000 - val_loss: 7535321.0000 - val_mean_absolute_error: 7535321.0000\n",
            "Epoch 349/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13683434.0000 - mean_absolute_error: 13683434.0000\n",
            "Epoch 00349: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13814442.0000 - mean_absolute_error: 13814442.0000 - val_loss: 7510943.0000 - val_mean_absolute_error: 7510943.0000\n",
            "Epoch 350/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14121069.0000 - mean_absolute_error: 14121069.0000\n",
            "Epoch 00350: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13789214.0000 - mean_absolute_error: 13789214.0000 - val_loss: 7535788.0000 - val_mean_absolute_error: 7535788.0000\n",
            "Epoch 351/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13975904.0000 - mean_absolute_error: 13975904.0000\n",
            "Epoch 00351: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13786562.0000 - mean_absolute_error: 13786562.0000 - val_loss: 7547523.0000 - val_mean_absolute_error: 7547523.0000\n",
            "Epoch 352/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13792211.0000 - mean_absolute_error: 13792211.0000\n",
            "Epoch 00352: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13792211.0000 - mean_absolute_error: 13792211.0000 - val_loss: 7514681.0000 - val_mean_absolute_error: 7514681.0000\n",
            "Epoch 353/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13895462.0000 - mean_absolute_error: 13895462.0000\n",
            "Epoch 00353: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13785346.0000 - mean_absolute_error: 13785346.0000 - val_loss: 7519213.5000 - val_mean_absolute_error: 7519213.5000\n",
            "Epoch 354/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14015249.0000 - mean_absolute_error: 14015249.0000\n",
            "Epoch 00354: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13783472.0000 - mean_absolute_error: 13783472.0000 - val_loss: 7559408.0000 - val_mean_absolute_error: 7559408.0000\n",
            "Epoch 355/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13589210.0000 - mean_absolute_error: 13589210.0000\n",
            "Epoch 00355: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13781154.0000 - mean_absolute_error: 13781154.0000 - val_loss: 7531581.0000 - val_mean_absolute_error: 7531581.0000\n",
            "Epoch 356/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13783750.0000 - mean_absolute_error: 13783750.0000\n",
            "Epoch 00356: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13783750.0000 - mean_absolute_error: 13783750.0000 - val_loss: 7536318.5000 - val_mean_absolute_error: 7536318.5000\n",
            "Epoch 357/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13839335.0000 - mean_absolute_error: 13839335.0000\n",
            "Epoch 00357: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13799147.0000 - mean_absolute_error: 13799147.0000 - val_loss: 7523171.0000 - val_mean_absolute_error: 7523171.0000\n",
            "Epoch 358/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13741518.0000 - mean_absolute_error: 13741518.0000\n",
            "Epoch 00358: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13792166.0000 - mean_absolute_error: 13792166.0000 - val_loss: 7514868.0000 - val_mean_absolute_error: 7514868.0000\n",
            "Epoch 359/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 14008557.0000 - mean_absolute_error: 14008557.0000\n",
            "Epoch 00359: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13771022.0000 - mean_absolute_error: 13771022.0000 - val_loss: 7560569.5000 - val_mean_absolute_error: 7560569.5000\n",
            "Epoch 360/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 12387373.0000 - mean_absolute_error: 12387373.0000\n",
            "Epoch 00360: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13792722.0000 - mean_absolute_error: 13792722.0000 - val_loss: 7533001.5000 - val_mean_absolute_error: 7533001.5000\n",
            "Epoch 361/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13983276.0000 - mean_absolute_error: 13983276.0000\n",
            "Epoch 00361: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13778416.0000 - mean_absolute_error: 13778416.0000 - val_loss: 7532942.5000 - val_mean_absolute_error: 7532942.5000\n",
            "Epoch 362/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13779533.0000 - mean_absolute_error: 13779533.0000\n",
            "Epoch 00362: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13779533.0000 - mean_absolute_error: 13779533.0000 - val_loss: 7517031.0000 - val_mean_absolute_error: 7517031.0000\n",
            "Epoch 363/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13798685.0000 - mean_absolute_error: 13798685.0000\n",
            "Epoch 00363: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13798685.0000 - mean_absolute_error: 13798685.0000 - val_loss: 7544073.5000 - val_mean_absolute_error: 7544073.5000\n",
            "Epoch 364/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13929551.0000 - mean_absolute_error: 13929551.0000\n",
            "Epoch 00364: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13786627.0000 - mean_absolute_error: 13786627.0000 - val_loss: 7530961.5000 - val_mean_absolute_error: 7530961.5000\n",
            "Epoch 365/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 11726807.0000 - mean_absolute_error: 11726807.0000\n",
            "Epoch 00365: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13815058.0000 - mean_absolute_error: 13815058.0000 - val_loss: 7565653.5000 - val_mean_absolute_error: 7565653.5000\n",
            "Epoch 366/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 13049477.0000 - mean_absolute_error: 13049477.0000\n",
            "Epoch 00366: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13828264.0000 - mean_absolute_error: 13828264.0000 - val_loss: 7520657.5000 - val_mean_absolute_error: 7520657.5000\n",
            "Epoch 367/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13783282.0000 - mean_absolute_error: 13783282.0000\n",
            "Epoch 00367: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13783282.0000 - mean_absolute_error: 13783282.0000 - val_loss: 7546136.0000 - val_mean_absolute_error: 7546136.0000\n",
            "Epoch 368/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 14026530.0000 - mean_absolute_error: 14026530.0000\n",
            "Epoch 00368: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13792805.0000 - mean_absolute_error: 13792805.0000 - val_loss: 7580173.5000 - val_mean_absolute_error: 7580173.5000\n",
            "Epoch 369/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13708078.0000 - mean_absolute_error: 13708078.0000\n",
            "Epoch 00369: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13794141.0000 - mean_absolute_error: 13794141.0000 - val_loss: 7554283.0000 - val_mean_absolute_error: 7554283.0000\n",
            "Epoch 370/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 14006202.0000 - mean_absolute_error: 14006202.0000\n",
            "Epoch 00370: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13805464.0000 - mean_absolute_error: 13805464.0000 - val_loss: 7528325.5000 - val_mean_absolute_error: 7528325.5000\n",
            "Epoch 371/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13798288.0000 - mean_absolute_error: 13798288.0000\n",
            "Epoch 00371: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13784267.0000 - mean_absolute_error: 13784267.0000 - val_loss: 7540364.0000 - val_mean_absolute_error: 7540364.0000\n",
            "Epoch 372/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13455086.0000 - mean_absolute_error: 13455086.0000\n",
            "Epoch 00372: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13779302.0000 - mean_absolute_error: 13779302.0000 - val_loss: 7533789.0000 - val_mean_absolute_error: 7533789.0000\n",
            "Epoch 373/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13684308.0000 - mean_absolute_error: 13684308.0000\n",
            "Epoch 00373: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13770437.0000 - mean_absolute_error: 13770437.0000 - val_loss: 7524290.5000 - val_mean_absolute_error: 7524290.5000\n",
            "Epoch 374/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14015246.0000 - mean_absolute_error: 14015246.0000\n",
            "Epoch 00374: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13788718.0000 - mean_absolute_error: 13788718.0000 - val_loss: 7545445.5000 - val_mean_absolute_error: 7545445.5000\n",
            "Epoch 375/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13631710.0000 - mean_absolute_error: 13631710.0000\n",
            "Epoch 00375: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13767768.0000 - mean_absolute_error: 13767768.0000 - val_loss: 7535188.0000 - val_mean_absolute_error: 7535188.0000\n",
            "Epoch 376/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13983335.0000 - mean_absolute_error: 13983335.0000\n",
            "Epoch 00376: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13802726.0000 - mean_absolute_error: 13802726.0000 - val_loss: 7571328.0000 - val_mean_absolute_error: 7571328.0000\n",
            "Epoch 377/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13779889.0000 - mean_absolute_error: 13779889.0000\n",
            "Epoch 00377: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13782074.0000 - mean_absolute_error: 13782074.0000 - val_loss: 7521745.0000 - val_mean_absolute_error: 7521745.0000\n",
            "Epoch 378/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13690170.0000 - mean_absolute_error: 13690170.0000\n",
            "Epoch 00378: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765638.0000 - mean_absolute_error: 13765638.0000 - val_loss: 7534240.0000 - val_mean_absolute_error: 7534240.0000\n",
            "Epoch 379/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13768939.0000 - mean_absolute_error: 13768939.0000\n",
            "Epoch 00379: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13768939.0000 - mean_absolute_error: 13768939.0000 - val_loss: 7549153.5000 - val_mean_absolute_error: 7549153.5000\n",
            "Epoch 380/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13849682.0000 - mean_absolute_error: 13849682.0000\n",
            "Epoch 00380: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13786491.0000 - mean_absolute_error: 13786491.0000 - val_loss: 7522729.0000 - val_mean_absolute_error: 7522729.0000\n",
            "Epoch 381/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13686990.0000 - mean_absolute_error: 13686990.0000\n",
            "Epoch 00381: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13762277.0000 - mean_absolute_error: 13762277.0000 - val_loss: 7543926.5000 - val_mean_absolute_error: 7543926.5000\n",
            "Epoch 382/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13795251.0000 - mean_absolute_error: 13795251.0000\n",
            "Epoch 00382: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13795251.0000 - mean_absolute_error: 13795251.0000 - val_loss: 7567056.0000 - val_mean_absolute_error: 7567056.0000\n",
            "Epoch 383/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13795216.0000 - mean_absolute_error: 13795216.0000\n",
            "Epoch 00383: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13795216.0000 - mean_absolute_error: 13795216.0000 - val_loss: 7526577.5000 - val_mean_absolute_error: 7526577.5000\n",
            "Epoch 384/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13449982.0000 - mean_absolute_error: 13449982.0000\n",
            "Epoch 00384: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13772675.0000 - mean_absolute_error: 13772675.0000 - val_loss: 7529881.0000 - val_mean_absolute_error: 7529881.0000\n",
            "Epoch 385/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13839986.0000 - mean_absolute_error: 13839986.0000\n",
            "Epoch 00385: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13788422.0000 - mean_absolute_error: 13788422.0000 - val_loss: 7575069.0000 - val_mean_absolute_error: 7575069.0000\n",
            "Epoch 386/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13873526.0000 - mean_absolute_error: 13873526.0000\n",
            "Epoch 00386: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13769928.0000 - mean_absolute_error: 13769928.0000 - val_loss: 7532167.0000 - val_mean_absolute_error: 7532167.0000\n",
            "Epoch 387/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13618983.0000 - mean_absolute_error: 13618983.0000\n",
            "Epoch 00387: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13767850.0000 - mean_absolute_error: 13767850.0000 - val_loss: 7521473.0000 - val_mean_absolute_error: 7521473.0000\n",
            "Epoch 388/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13707412.0000 - mean_absolute_error: 13707412.0000\n",
            "Epoch 00388: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13776114.0000 - mean_absolute_error: 13776114.0000 - val_loss: 7538069.5000 - val_mean_absolute_error: 7538069.5000\n",
            "Epoch 389/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13523593.0000 - mean_absolute_error: 13523593.0000\n",
            "Epoch 00389: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13791741.0000 - mean_absolute_error: 13791741.0000 - val_loss: 7540436.0000 - val_mean_absolute_error: 7540436.0000\n",
            "Epoch 390/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13747500.0000 - mean_absolute_error: 13747500.0000\n",
            "Epoch 00390: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13777035.0000 - mean_absolute_error: 13777035.0000 - val_loss: 7536459.0000 - val_mean_absolute_error: 7536459.0000\n",
            "Epoch 391/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13772115.0000 - mean_absolute_error: 13772115.0000\n",
            "Epoch 00391: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13772115.0000 - mean_absolute_error: 13772115.0000 - val_loss: 7520252.0000 - val_mean_absolute_error: 7520252.0000\n",
            "Epoch 392/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13717155.0000 - mean_absolute_error: 13717155.0000\n",
            "Epoch 00392: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13772248.0000 - mean_absolute_error: 13772248.0000 - val_loss: 7555945.0000 - val_mean_absolute_error: 7555945.0000\n",
            "Epoch 393/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13887904.0000 - mean_absolute_error: 13887904.0000\n",
            "Epoch 00393: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13768528.0000 - mean_absolute_error: 13768528.0000 - val_loss: 7525947.0000 - val_mean_absolute_error: 7525947.0000\n",
            "Epoch 394/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13767779.0000 - mean_absolute_error: 13767779.0000\n",
            "Epoch 00394: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13767779.0000 - mean_absolute_error: 13767779.0000 - val_loss: 7536421.5000 - val_mean_absolute_error: 7536421.5000\n",
            "Epoch 395/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13790122.0000 - mean_absolute_error: 13790122.0000\n",
            "Epoch 00395: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13790122.0000 - mean_absolute_error: 13790122.0000 - val_loss: 7551353.5000 - val_mean_absolute_error: 7551353.5000\n",
            "Epoch 396/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13706587.0000 - mean_absolute_error: 13706587.0000\n",
            "Epoch 00396: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13775890.0000 - mean_absolute_error: 13775890.0000 - val_loss: 7522105.0000 - val_mean_absolute_error: 7522105.0000\n",
            "Epoch 397/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13488521.0000 - mean_absolute_error: 13488521.0000\n",
            "Epoch 00397: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13772982.0000 - mean_absolute_error: 13772982.0000 - val_loss: 7520537.0000 - val_mean_absolute_error: 7520537.0000\n",
            "Epoch 398/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13761878.0000 - mean_absolute_error: 13761878.0000\n",
            "Epoch 00398: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13761878.0000 - mean_absolute_error: 13761878.0000 - val_loss: 7536291.0000 - val_mean_absolute_error: 7536291.0000\n",
            "Epoch 399/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13769122.0000 - mean_absolute_error: 13769122.0000\n",
            "Epoch 00399: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13769122.0000 - mean_absolute_error: 13769122.0000 - val_loss: 7550285.0000 - val_mean_absolute_error: 7550285.0000\n",
            "Epoch 400/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13762093.0000 - mean_absolute_error: 13762093.0000\n",
            "Epoch 00400: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13762093.0000 - mean_absolute_error: 13762093.0000 - val_loss: 7537138.5000 - val_mean_absolute_error: 7537138.5000\n",
            "Epoch 401/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13692606.0000 - mean_absolute_error: 13692606.0000\n",
            "Epoch 00401: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13762707.0000 - mean_absolute_error: 13762707.0000 - val_loss: 7521471.0000 - val_mean_absolute_error: 7521471.0000\n",
            "Epoch 402/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13961123.0000 - mean_absolute_error: 13961123.0000\n",
            "Epoch 00402: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13767365.0000 - mean_absolute_error: 13767365.0000 - val_loss: 7536948.0000 - val_mean_absolute_error: 7536948.0000\n",
            "Epoch 403/500\n",
            " 1/20 [>.............................] - ETA: 0s - loss: 14213563.0000 - mean_absolute_error: 14213563.0000\n",
            "Epoch 00403: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 13834176.0000 - mean_absolute_error: 13834176.0000 - val_loss: 7580402.5000 - val_mean_absolute_error: 7580402.5000\n",
            "Epoch 404/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13757661.0000 - mean_absolute_error: 13757661.0000\n",
            "Epoch 00404: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13757661.0000 - mean_absolute_error: 13757661.0000 - val_loss: 7521753.5000 - val_mean_absolute_error: 7521753.5000\n",
            "Epoch 405/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13625153.0000 - mean_absolute_error: 13625153.0000\n",
            "Epoch 00405: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13800358.0000 - mean_absolute_error: 13800358.0000 - val_loss: 7519241.5000 - val_mean_absolute_error: 7519241.5000\n",
            "Epoch 406/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13892113.0000 - mean_absolute_error: 13892113.0000\n",
            "Epoch 00406: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13757051.0000 - mean_absolute_error: 13757051.0000 - val_loss: 7545113.0000 - val_mean_absolute_error: 7545113.0000\n",
            "Epoch 407/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13665118.0000 - mean_absolute_error: 13665118.0000\n",
            "Epoch 00407: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13770488.0000 - mean_absolute_error: 13770488.0000 - val_loss: 7549102.5000 - val_mean_absolute_error: 7549102.5000\n",
            "Epoch 408/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13762811.0000 - mean_absolute_error: 13762811.0000\n",
            "Epoch 00408: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13762811.0000 - mean_absolute_error: 13762811.0000 - val_loss: 7533370.5000 - val_mean_absolute_error: 7533370.5000\n",
            "Epoch 409/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13591715.0000 - mean_absolute_error: 13591715.0000\n",
            "Epoch 00409: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13766301.0000 - mean_absolute_error: 13766301.0000 - val_loss: 7554527.0000 - val_mean_absolute_error: 7554527.0000\n",
            "Epoch 410/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13782013.0000 - mean_absolute_error: 13782013.0000\n",
            "Epoch 00410: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13783376.0000 - mean_absolute_error: 13783376.0000 - val_loss: 7542557.5000 - val_mean_absolute_error: 7542557.5000\n",
            "Epoch 411/500\n",
            "13/20 [==================>...........] - ETA: 0s - loss: 12793532.0000 - mean_absolute_error: 12793532.0000\n",
            "Epoch 00411: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13766464.0000 - mean_absolute_error: 13766464.0000 - val_loss: 7526505.5000 - val_mean_absolute_error: 7526505.5000\n",
            "Epoch 412/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13767250.0000 - mean_absolute_error: 13767250.0000\n",
            "Epoch 00412: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13767250.0000 - mean_absolute_error: 13767250.0000 - val_loss: 7537081.5000 - val_mean_absolute_error: 7537081.5000\n",
            "Epoch 413/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13789253.0000 - mean_absolute_error: 13789253.0000\n",
            "Epoch 00413: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13789253.0000 - mean_absolute_error: 13789253.0000 - val_loss: 7520379.0000 - val_mean_absolute_error: 7520379.0000\n",
            "Epoch 414/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13444410.0000 - mean_absolute_error: 13444410.0000\n",
            "Epoch 00414: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765258.0000 - mean_absolute_error: 13765258.0000 - val_loss: 7548305.5000 - val_mean_absolute_error: 7548305.5000\n",
            "Epoch 415/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13761933.0000 - mean_absolute_error: 13761933.0000\n",
            "Epoch 00415: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13761933.0000 - mean_absolute_error: 13761933.0000 - val_loss: 7571630.5000 - val_mean_absolute_error: 7571630.5000\n",
            "Epoch 416/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14008302.0000 - mean_absolute_error: 14008302.0000\n",
            "Epoch 00416: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13765645.0000 - mean_absolute_error: 13765645.0000 - val_loss: 7533508.0000 - val_mean_absolute_error: 7533508.0000\n",
            "Epoch 417/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13690215.0000 - mean_absolute_error: 13690215.0000\n",
            "Epoch 00417: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765475.0000 - mean_absolute_error: 13765475.0000 - val_loss: 7528494.5000 - val_mean_absolute_error: 7528494.5000\n",
            "Epoch 418/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13934724.0000 - mean_absolute_error: 13934724.0000\n",
            "Epoch 00418: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13782173.0000 - mean_absolute_error: 13782173.0000 - val_loss: 7596301.5000 - val_mean_absolute_error: 7596301.5000\n",
            "Epoch 419/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13760331.0000 - mean_absolute_error: 13760331.0000\n",
            "Epoch 00419: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760331.0000 - mean_absolute_error: 13760331.0000 - val_loss: 7527945.0000 - val_mean_absolute_error: 7527945.0000\n",
            "Epoch 420/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13622299.0000 - mean_absolute_error: 13622299.0000\n",
            "Epoch 00420: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13776491.0000 - mean_absolute_error: 13776491.0000 - val_loss: 7531255.0000 - val_mean_absolute_error: 7531255.0000\n",
            "Epoch 421/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13474064.0000 - mean_absolute_error: 13474064.0000\n",
            "Epoch 00421: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13753762.0000 - mean_absolute_error: 13753762.0000 - val_loss: 7559833.0000 - val_mean_absolute_error: 7559833.0000\n",
            "Epoch 422/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13714779.0000 - mean_absolute_error: 13714779.0000\n",
            "Epoch 00422: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765389.0000 - mean_absolute_error: 13765389.0000 - val_loss: 7529362.5000 - val_mean_absolute_error: 7529362.5000\n",
            "Epoch 423/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14101249.0000 - mean_absolute_error: 14101249.0000\n",
            "Epoch 00423: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13791818.0000 - mean_absolute_error: 13791818.0000 - val_loss: 7560021.0000 - val_mean_absolute_error: 7560021.0000\n",
            "Epoch 424/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13933491.0000 - mean_absolute_error: 13933491.0000\n",
            "Epoch 00424: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13786453.0000 - mean_absolute_error: 13786453.0000 - val_loss: 7522430.5000 - val_mean_absolute_error: 7522430.5000\n",
            "Epoch 425/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13756631.0000 - mean_absolute_error: 13756631.0000\n",
            "Epoch 00425: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13755486.0000 - mean_absolute_error: 13755486.0000 - val_loss: 7565501.0000 - val_mean_absolute_error: 7565501.0000\n",
            "Epoch 426/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13731138.0000 - mean_absolute_error: 13731138.0000\n",
            "Epoch 00426: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13773418.0000 - mean_absolute_error: 13773418.0000 - val_loss: 7529865.5000 - val_mean_absolute_error: 7529865.5000\n",
            "Epoch 427/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13789594.0000 - mean_absolute_error: 13789594.0000\n",
            "Epoch 00427: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13758168.0000 - mean_absolute_error: 13758168.0000 - val_loss: 7559534.5000 - val_mean_absolute_error: 7559534.5000\n",
            "Epoch 428/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13766822.0000 - mean_absolute_error: 13766822.0000\n",
            "Epoch 00428: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13766822.0000 - mean_absolute_error: 13766822.0000 - val_loss: 7529325.0000 - val_mean_absolute_error: 7529325.0000\n",
            "Epoch 429/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13760512.0000 - mean_absolute_error: 13760512.0000\n",
            "Epoch 00429: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760512.0000 - mean_absolute_error: 13760512.0000 - val_loss: 7539341.0000 - val_mean_absolute_error: 7539341.0000\n",
            "Epoch 430/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13707599.0000 - mean_absolute_error: 13707599.0000\n",
            "Epoch 00430: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13758939.0000 - mean_absolute_error: 13758939.0000 - val_loss: 7556621.5000 - val_mean_absolute_error: 7556621.5000\n",
            "Epoch 431/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13674299.0000 - mean_absolute_error: 13674299.0000\n",
            "Epoch 00431: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13752062.0000 - mean_absolute_error: 13752062.0000 - val_loss: 7526884.0000 - val_mean_absolute_error: 7526884.0000\n",
            "Epoch 432/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13757424.0000 - mean_absolute_error: 13757424.0000\n",
            "Epoch 00432: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13757424.0000 - mean_absolute_error: 13757424.0000 - val_loss: 7542537.5000 - val_mean_absolute_error: 7542537.5000\n",
            "Epoch 433/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14021167.0000 - mean_absolute_error: 14021167.0000\n",
            "Epoch 00433: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13751931.0000 - mean_absolute_error: 13751931.0000 - val_loss: 7552326.5000 - val_mean_absolute_error: 7552326.5000\n",
            "Epoch 434/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13749237.0000 - mean_absolute_error: 13749237.0000\n",
            "Epoch 00434: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13749237.0000 - mean_absolute_error: 13749237.0000 - val_loss: 7545888.0000 - val_mean_absolute_error: 7545888.0000\n",
            "Epoch 435/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13989549.0000 - mean_absolute_error: 13989549.0000\n",
            "Epoch 00435: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13746442.0000 - mean_absolute_error: 13746442.0000 - val_loss: 7543737.5000 - val_mean_absolute_error: 7543737.5000\n",
            "Epoch 436/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13755374.0000 - mean_absolute_error: 13755374.0000\n",
            "Epoch 00436: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13755374.0000 - mean_absolute_error: 13755374.0000 - val_loss: 7540419.0000 - val_mean_absolute_error: 7540419.0000\n",
            "Epoch 437/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13747832.0000 - mean_absolute_error: 13747832.0000\n",
            "Epoch 00437: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13747832.0000 - mean_absolute_error: 13747832.0000 - val_loss: 7529850.5000 - val_mean_absolute_error: 7529850.5000\n",
            "Epoch 438/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13764179.0000 - mean_absolute_error: 13764179.0000\n",
            "Epoch 00438: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13764179.0000 - mean_absolute_error: 13764179.0000 - val_loss: 7579995.0000 - val_mean_absolute_error: 7579995.0000\n",
            "Epoch 439/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13746166.0000 - mean_absolute_error: 13746166.0000\n",
            "Epoch 00439: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13746166.0000 - mean_absolute_error: 13746166.0000 - val_loss: 7534915.0000 - val_mean_absolute_error: 7534915.0000\n",
            "Epoch 440/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13425289.0000 - mean_absolute_error: 13425289.0000\n",
            "Epoch 00440: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13749970.0000 - mean_absolute_error: 13749970.0000 - val_loss: 7527494.5000 - val_mean_absolute_error: 7527494.5000\n",
            "Epoch 441/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13765472.0000 - mean_absolute_error: 13765472.0000\n",
            "Epoch 00441: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765472.0000 - mean_absolute_error: 13765472.0000 - val_loss: 7556212.0000 - val_mean_absolute_error: 7556212.0000\n",
            "Epoch 442/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13941768.0000 - mean_absolute_error: 13941768.0000\n",
            "Epoch 00442: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13750453.0000 - mean_absolute_error: 13750453.0000 - val_loss: 7531797.0000 - val_mean_absolute_error: 7531797.0000\n",
            "Epoch 443/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13745010.0000 - mean_absolute_error: 13745010.0000\n",
            "Epoch 00443: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13745010.0000 - mean_absolute_error: 13745010.0000 - val_loss: 7565777.5000 - val_mean_absolute_error: 7565777.5000\n",
            "Epoch 444/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13464642.0000 - mean_absolute_error: 13464642.0000\n",
            "Epoch 00444: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13744970.0000 - mean_absolute_error: 13744970.0000 - val_loss: 7547689.5000 - val_mean_absolute_error: 7547689.5000\n",
            "Epoch 445/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13550314.0000 - mean_absolute_error: 13550314.0000\n",
            "Epoch 00445: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760200.0000 - mean_absolute_error: 13760200.0000 - val_loss: 7527797.5000 - val_mean_absolute_error: 7527797.5000\n",
            "Epoch 446/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13554499.0000 - mean_absolute_error: 13554499.0000\n",
            "Epoch 00446: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13747536.0000 - mean_absolute_error: 13747536.0000 - val_loss: 7556718.5000 - val_mean_absolute_error: 7556718.5000\n",
            "Epoch 447/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13704682.0000 - mean_absolute_error: 13704682.0000\n",
            "Epoch 00447: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13742643.0000 - mean_absolute_error: 13742643.0000 - val_loss: 7547001.5000 - val_mean_absolute_error: 7547001.5000\n",
            "Epoch 448/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13102081.0000 - mean_absolute_error: 13102081.0000\n",
            "Epoch 00448: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13753392.0000 - mean_absolute_error: 13753392.0000 - val_loss: 7525635.0000 - val_mean_absolute_error: 7525635.0000\n",
            "Epoch 449/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13778769.0000 - mean_absolute_error: 13778769.0000\n",
            "Epoch 00449: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13756488.0000 - mean_absolute_error: 13756488.0000 - val_loss: 7526386.5000 - val_mean_absolute_error: 7526386.5000\n",
            "Epoch 450/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13642925.0000 - mean_absolute_error: 13642925.0000\n",
            "Epoch 00450: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13750579.0000 - mean_absolute_error: 13750579.0000 - val_loss: 7532495.0000 - val_mean_absolute_error: 7532495.0000\n",
            "Epoch 451/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 14023664.0000 - mean_absolute_error: 14023664.0000\n",
            "Epoch 00451: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13757187.0000 - mean_absolute_error: 13757187.0000 - val_loss: 7571873.0000 - val_mean_absolute_error: 7571873.0000\n",
            "Epoch 452/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13618008.0000 - mean_absolute_error: 13618008.0000\n",
            "Epoch 00452: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13740282.0000 - mean_absolute_error: 13740282.0000 - val_loss: 7545013.5000 - val_mean_absolute_error: 7545013.5000\n",
            "Epoch 453/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13742701.0000 - mean_absolute_error: 13742701.0000\n",
            "Epoch 00453: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13742701.0000 - mean_absolute_error: 13742701.0000 - val_loss: 7543194.5000 - val_mean_absolute_error: 7543194.5000\n",
            "Epoch 454/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13532121.0000 - mean_absolute_error: 13532121.0000\n",
            "Epoch 00454: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13754904.0000 - mean_absolute_error: 13754904.0000 - val_loss: 7554238.5000 - val_mean_absolute_error: 7554238.5000\n",
            "Epoch 455/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13743539.0000 - mean_absolute_error: 13743539.0000\n",
            "Epoch 00455: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13743539.0000 - mean_absolute_error: 13743539.0000 - val_loss: 7529891.0000 - val_mean_absolute_error: 7529891.0000\n",
            "Epoch 456/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13747602.0000 - mean_absolute_error: 13747602.0000\n",
            "Epoch 00456: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13747602.0000 - mean_absolute_error: 13747602.0000 - val_loss: 7536025.0000 - val_mean_absolute_error: 7536025.0000\n",
            "Epoch 457/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 14018110.0000 - mean_absolute_error: 14018110.0000\n",
            "Epoch 00457: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13759179.0000 - mean_absolute_error: 13759179.0000 - val_loss: 7553878.5000 - val_mean_absolute_error: 7553878.5000\n",
            "Epoch 458/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13714290.0000 - mean_absolute_error: 13714290.0000\n",
            "Epoch 00458: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13749925.0000 - mean_absolute_error: 13749925.0000 - val_loss: 7560617.0000 - val_mean_absolute_error: 7560617.0000\n",
            "Epoch 459/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13728371.0000 - mean_absolute_error: 13728371.0000\n",
            "Epoch 00459: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13728371.0000 - mean_absolute_error: 13728371.0000 - val_loss: 7534143.0000 - val_mean_absolute_error: 7534143.0000\n",
            "Epoch 460/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13745696.0000 - mean_absolute_error: 13745696.0000\n",
            "Epoch 00460: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13745696.0000 - mean_absolute_error: 13745696.0000 - val_loss: 7531736.0000 - val_mean_absolute_error: 7531736.0000\n",
            "Epoch 461/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13994655.0000 - mean_absolute_error: 13994655.0000\n",
            "Epoch 00461: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13794933.0000 - mean_absolute_error: 13794933.0000 - val_loss: 7563109.5000 - val_mean_absolute_error: 7563109.5000\n",
            "Epoch 462/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13747720.0000 - mean_absolute_error: 13747720.0000\n",
            "Epoch 00462: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13747720.0000 - mean_absolute_error: 13747720.0000 - val_loss: 7526625.0000 - val_mean_absolute_error: 7526625.0000\n",
            "Epoch 463/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13793645.0000 - mean_absolute_error: 13793645.0000\n",
            "Epoch 00463: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13738090.0000 - mean_absolute_error: 13738090.0000 - val_loss: 7536361.0000 - val_mean_absolute_error: 7536361.0000\n",
            "Epoch 464/500\n",
            "15/20 [=====================>........] - ETA: 0s - loss: 13823219.0000 - mean_absolute_error: 13823219.0000\n",
            "Epoch 00464: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13735598.0000 - mean_absolute_error: 13735598.0000 - val_loss: 7539398.5000 - val_mean_absolute_error: 7539398.5000\n",
            "Epoch 465/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13745866.0000 - mean_absolute_error: 13745866.0000\n",
            "Epoch 00465: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13745866.0000 - mean_absolute_error: 13745866.0000 - val_loss: 7547401.5000 - val_mean_absolute_error: 7547401.5000\n",
            "Epoch 466/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13740827.0000 - mean_absolute_error: 13740827.0000\n",
            "Epoch 00466: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13740827.0000 - mean_absolute_error: 13740827.0000 - val_loss: 7542313.5000 - val_mean_absolute_error: 7542313.5000\n",
            "Epoch 467/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13731771.0000 - mean_absolute_error: 13731771.0000\n",
            "Epoch 00467: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13731771.0000 - mean_absolute_error: 13731771.0000 - val_loss: 7557147.0000 - val_mean_absolute_error: 7557147.0000\n",
            "Epoch 468/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13427284.0000 - mean_absolute_error: 13427284.0000\n",
            "Epoch 00468: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760136.0000 - mean_absolute_error: 13760136.0000 - val_loss: 7526977.5000 - val_mean_absolute_error: 7526977.5000\n",
            "Epoch 469/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13748571.0000 - mean_absolute_error: 13748571.0000\n",
            "Epoch 00469: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13748571.0000 - mean_absolute_error: 13748571.0000 - val_loss: 7542080.0000 - val_mean_absolute_error: 7542080.0000\n",
            "Epoch 470/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13769419.0000 - mean_absolute_error: 13769419.0000\n",
            "Epoch 00470: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13769419.0000 - mean_absolute_error: 13769419.0000 - val_loss: 7547274.5000 - val_mean_absolute_error: 7547274.5000\n",
            "Epoch 471/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13765784.0000 - mean_absolute_error: 13765784.0000\n",
            "Epoch 00471: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13765784.0000 - mean_absolute_error: 13765784.0000 - val_loss: 7529553.0000 - val_mean_absolute_error: 7529553.0000\n",
            "Epoch 472/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13728323.0000 - mean_absolute_error: 13728323.0000\n",
            "Epoch 00472: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13728323.0000 - mean_absolute_error: 13728323.0000 - val_loss: 7566003.0000 - val_mean_absolute_error: 7566003.0000\n",
            "Epoch 473/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13742346.0000 - mean_absolute_error: 13742346.0000\n",
            "Epoch 00473: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13742346.0000 - mean_absolute_error: 13742346.0000 - val_loss: 7579353.5000 - val_mean_absolute_error: 7579353.5000\n",
            "Epoch 474/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13713236.0000 - mean_absolute_error: 13713236.0000\n",
            "Epoch 00474: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13734648.0000 - mean_absolute_error: 13734648.0000 - val_loss: 7535859.0000 - val_mean_absolute_error: 7535859.0000\n",
            "Epoch 475/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13983867.0000 - mean_absolute_error: 13983867.0000\n",
            "Epoch 00475: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760413.0000 - mean_absolute_error: 13760413.0000 - val_loss: 7568789.5000 - val_mean_absolute_error: 7568789.5000\n",
            "Epoch 476/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13602783.0000 - mean_absolute_error: 13602783.0000\n",
            "Epoch 00476: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13732509.0000 - mean_absolute_error: 13732509.0000 - val_loss: 7538049.0000 - val_mean_absolute_error: 7538049.0000\n",
            "Epoch 477/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13719354.0000 - mean_absolute_error: 13719354.0000\n",
            "Epoch 00477: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13730853.0000 - mean_absolute_error: 13730853.0000 - val_loss: 7563796.0000 - val_mean_absolute_error: 7563796.0000\n",
            "Epoch 478/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13730522.0000 - mean_absolute_error: 13730522.0000\n",
            "Epoch 00478: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13730522.0000 - mean_absolute_error: 13730522.0000 - val_loss: 7561581.5000 - val_mean_absolute_error: 7561581.5000\n",
            "Epoch 479/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13730874.0000 - mean_absolute_error: 13730874.0000\n",
            "Epoch 00479: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13730874.0000 - mean_absolute_error: 13730874.0000 - val_loss: 7540221.0000 - val_mean_absolute_error: 7540221.0000\n",
            "Epoch 480/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13760462.0000 - mean_absolute_error: 13760462.0000\n",
            "Epoch 00480: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13760462.0000 - mean_absolute_error: 13760462.0000 - val_loss: 7536298.5000 - val_mean_absolute_error: 7536298.5000\n",
            "Epoch 481/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13790782.0000 - mean_absolute_error: 13790782.0000\n",
            "Epoch 00481: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13754718.0000 - mean_absolute_error: 13754718.0000 - val_loss: 7600377.5000 - val_mean_absolute_error: 7600377.5000\n",
            "Epoch 482/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13745651.0000 - mean_absolute_error: 13745651.0000\n",
            "Epoch 00482: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13745651.0000 - mean_absolute_error: 13745651.0000 - val_loss: 7531336.0000 - val_mean_absolute_error: 7531336.0000\n",
            "Epoch 483/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13730200.0000 - mean_absolute_error: 13730200.0000\n",
            "Epoch 00483: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13730200.0000 - mean_absolute_error: 13730200.0000 - val_loss: 7536209.5000 - val_mean_absolute_error: 7536209.5000\n",
            "Epoch 484/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13936968.0000 - mean_absolute_error: 13936968.0000\n",
            "Epoch 00484: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13736650.0000 - mean_absolute_error: 13736650.0000 - val_loss: 7551199.0000 - val_mean_absolute_error: 7551199.0000\n",
            "Epoch 485/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13256587.0000 - mean_absolute_error: 13256587.0000\n",
            "Epoch 00485: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13732867.0000 - mean_absolute_error: 13732867.0000 - val_loss: 7543349.5000 - val_mean_absolute_error: 7543349.5000\n",
            "Epoch 486/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13861167.0000 - mean_absolute_error: 13861167.0000\n",
            "Epoch 00486: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13729216.0000 - mean_absolute_error: 13729216.0000 - val_loss: 7561791.0000 - val_mean_absolute_error: 7561791.0000\n",
            "Epoch 487/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13837677.0000 - mean_absolute_error: 13837677.0000\n",
            "Epoch 00487: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13728086.0000 - mean_absolute_error: 13728086.0000 - val_loss: 7561014.5000 - val_mean_absolute_error: 7561014.5000\n",
            "Epoch 488/500\n",
            "17/20 [========================>.....] - ETA: 0s - loss: 13530459.0000 - mean_absolute_error: 13530459.0000\n",
            "Epoch 00488: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13737552.0000 - mean_absolute_error: 13737552.0000 - val_loss: 7556350.5000 - val_mean_absolute_error: 7556350.5000\n",
            "Epoch 489/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13617444.0000 - mean_absolute_error: 13617444.0000\n",
            "Epoch 00489: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13718013.0000 - mean_absolute_error: 13718013.0000 - val_loss: 7534641.0000 - val_mean_absolute_error: 7534641.0000\n",
            "Epoch 490/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13689636.0000 - mean_absolute_error: 13689636.0000\n",
            "Epoch 00490: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13730664.0000 - mean_absolute_error: 13730664.0000 - val_loss: 7537602.5000 - val_mean_absolute_error: 7537602.5000\n",
            "Epoch 491/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13723293.0000 - mean_absolute_error: 13723293.0000\n",
            "Epoch 00491: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13723293.0000 - mean_absolute_error: 13723293.0000 - val_loss: 7546796.0000 - val_mean_absolute_error: 7546796.0000\n",
            "Epoch 492/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13829331.0000 - mean_absolute_error: 13829331.0000\n",
            "Epoch 00492: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13750403.0000 - mean_absolute_error: 13750403.0000 - val_loss: 7538073.5000 - val_mean_absolute_error: 7538073.5000\n",
            "Epoch 493/500\n",
            "20/20 [==============================] - ETA: 0s - loss: 13750307.0000 - mean_absolute_error: 13750307.0000\n",
            "Epoch 00493: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13750307.0000 - mean_absolute_error: 13750307.0000 - val_loss: 7580566.5000 - val_mean_absolute_error: 7580566.5000\n",
            "Epoch 494/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13926446.0000 - mean_absolute_error: 13926446.0000\n",
            "Epoch 00494: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13737134.0000 - mean_absolute_error: 13737134.0000 - val_loss: 7530165.5000 - val_mean_absolute_error: 7530165.5000\n",
            "Epoch 495/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13753069.0000 - mean_absolute_error: 13753069.0000\n",
            "Epoch 00495: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13719194.0000 - mean_absolute_error: 13719194.0000 - val_loss: 7544117.5000 - val_mean_absolute_error: 7544117.5000\n",
            "Epoch 496/500\n",
            "16/20 [=======================>......] - ETA: 0s - loss: 13740870.0000 - mean_absolute_error: 13740870.0000\n",
            "Epoch 00496: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 13731245.0000 - mean_absolute_error: 13731245.0000 - val_loss: 7539913.0000 - val_mean_absolute_error: 7539913.0000\n",
            "Epoch 497/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13888079.0000 - mean_absolute_error: 13888079.0000\n",
            "Epoch 00497: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13721837.0000 - mean_absolute_error: 13721837.0000 - val_loss: 7533393.5000 - val_mean_absolute_error: 7533393.5000\n",
            "Epoch 498/500\n",
            "18/20 [==========================>...] - ETA: 0s - loss: 13998414.0000 - mean_absolute_error: 13998414.0000\n",
            "Epoch 00498: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13721018.0000 - mean_absolute_error: 13721018.0000 - val_loss: 7553827.0000 - val_mean_absolute_error: 7553827.0000\n",
            "Epoch 499/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13803881.0000 - mean_absolute_error: 13803881.0000\n",
            "Epoch 00499: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13726738.0000 - mean_absolute_error: 13726738.0000 - val_loss: 7534149.0000 - val_mean_absolute_error: 7534149.0000\n",
            "Epoch 500/500\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 13842060.0000 - mean_absolute_error: 13842060.0000\n",
            "Epoch 00500: val_loss did not improve from 7454258.50000\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 13750662.0000 - mean_absolute_error: 13750662.0000 - val_loss: 7579777.0000 - val_mean_absolute_error: 7579777.0000\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 128)               768       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 165,633\n",
            "Trainable params: 165,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMdBKM-m4uvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load wights file of the best model :\n",
        "# wights_file = 'Weights-478--18738.19831.hdf5' # choose the best checkpoint \n",
        "# NN_model.load_weights(wights_file) # load it\n",
        "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-YVAHYJDEwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submission(prediction, sub_name):\n",
        "  my_submission = pd.DataFrame({'Id':pd.read_csv('test.csv').Id,'SalePrice':prediction})\n",
        "  my_submission.to_csv('{}.csv'.format(sub_name),index=False)\n",
        "  print('A submission file has been made')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4hYWoO-PQzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "bcf6c035-c60e-43ab-dcfe-8615dea54bec"
      },
      "source": [
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Test Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fca1602ee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qEAPKY1DHar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = NN_model.predict(test)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJs0uYb_NyJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e6d0762-efcc-4c22-f0e4-0ca2d7e0f896"
      },
      "source": [
        "#     \n",
        "mydata = np.array([[11,10,81,15,15]])\n",
        "# mydata = scaler.fit_transform(mydata)\n",
        "mydata"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11, 10, 81, 15, 15]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOAOPa2PElTI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b99695e-1ad5-4a4e-a7c3-7376d1d9d1ea"
      },
      "source": [
        "#  \n",
        "# pred = model.predict(X_train_t)\n",
        "pred = NN_model.predict(mydata)\n",
        "\n",
        "pred"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[38755260.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azuSX3TxOvDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2367625e-f1f9-4555-a971-3d040df98a35"
      },
      "source": [
        "\n",
        "marketvaluepred = 37397468 * 1.027 * 1.025 * 1.018 * 1.018\n",
        "marketvaluepred"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40797360.32446751"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    }
  ]
}